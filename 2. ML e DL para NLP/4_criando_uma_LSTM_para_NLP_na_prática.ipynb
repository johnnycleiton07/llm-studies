{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnrWEIhlrGeUGNDKBJDTk4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Criando uma LSTM para NLP na pr√°tica\n",
        "\n",
        "üíª [acessar este jupyter notebook no colab](https://colab.research.google.com/drive/1d5MYs5cEl-55JtO_AmEHIukaKRsY-nwA?usp=sharing)\n",
        "\n",
        "LSTM, que significa Long Short-Term Memory, √© um tipo de Rede Neural Recorrente (RNN) desenvolvida para superar as limita√ß√µes das RNNs tradicionais."
      ],
      "metadata": {
        "id": "M5FWLv_NkE9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Configura√ß√µes iniciais\n",
        "\n",
        "* `keras` √© uma biblioteca de c√≥digo aberto em Python que oferece uma interface de alto n√≠vel para a constru√ß√£o e treinamento de redes neurais. Foi desenvolvida com o objetivo de facilitar a experimenta√ß√£o r√°pida e a cria√ß√£o de modelos de aprendizado profundo de maneira simples e eficiente."
      ],
      "metadata": {
        "id": "yhFD1cAgkUsE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efe9nzaGgbgV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense\n",
        "from keras.utils import to_categorical\n",
        "from keras.initializers import Constant\n",
        "import os\n",
        "import zipfile\n",
        "import urllib.request"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `GloVe` (Global Vectors for Word Representation) √© um algoritmo de aprendizado n√£o supervisionado para a gera√ß√£o de representa√ß√µes de palavras (embeddings) a partir de co-ocorr√™ncias de palavras em um corpus de texto. Foi desenvolvido por pesquisadores da Universidade de Stanford."
      ],
      "metadata": {
        "id": "cP1vGXtTkydk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_url = \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "glove_file = \"glove.6B.zip\"\n",
        "glove_dir = \"glove.6B\"\n",
        "glove_txt = os.path.join(glove_dir, \"glove.6B.50d.txt\")\n",
        "\n",
        "if not os.path.exists(glove_txt):\n",
        "    if not os.path.exists(glove_file):\n",
        "        print(\"Baixando GloVe embeddings...\")\n",
        "        urllib.request.urlretrieve(glove_url, glove_file)\n",
        "\n",
        "    if not os.path.exists(glove_dir):\n",
        "        os.makedirs(glove_dir)\n",
        "        print(\"Extraindo GloVe embeddings...\")\n",
        "        with zipfile.ZipFile(glove_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(glove_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DtGzleXg0BA",
        "outputId": "4bc95b92-9d8c-438e-b667-14eaec23914b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando GloVe embeddings...\n",
            "Extraindo GloVe embeddings...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A fun√ß√£o abaixo abre o arquivo de texto j√° vetorizado (embeddings)"
      ],
      "metadata": {
        "id": "xjMu8MGBlsZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar_primeiras_linhas(caminho_arquivo, num_linhas=5):\n",
        "    try:\n",
        "        with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo:\n",
        "            for i in range(num_linhas):\n",
        "                linha = arquivo.readline()\n",
        "                if not linha:\n",
        "                    break\n",
        "                print(linha.strip())\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao ler o arquivo: {e}\")\n",
        "\n",
        "caminho_arquivo = '/content/glove.6B/glove.6B.200d.txt'\n",
        "mostrar_primeiras_linhas(caminho_arquivo, num_linhas=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQltHl8Ag_U6",
        "outputId": "12a5af65-2ed2-44a4-b728-ed417f893464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the -0.071549 0.093459 0.023738 -0.090339 0.056123 0.32547 -0.39796 -0.092139 0.061181 -0.1895 0.13061 0.14349 0.011479 0.38158 0.5403 -0.14088 0.24315 0.23036 -0.55339 0.048154 0.45662 3.2338 0.020199 0.049019 -0.014132 0.076017 -0.11527 0.2006 -0.077657 0.24328 0.16368 -0.34118 -0.06607 0.10152 0.038232 -0.17668 -0.88153 -0.33895 -0.035481 -0.55095 -0.016899 -0.43982 0.039004 0.40447 -0.2588 0.64594 0.26641 0.28009 -0.024625 0.63302 -0.317 0.10271 0.30886 0.097792 -0.38227 0.086552 0.047075 0.23511 -0.32127 -0.28538 0.1667 -0.0049707 -0.62714 -0.24904 0.29713 0.14379 -0.12325 -0.058178 -0.001029 -0.082126 0.36935 -0.00058442 0.34286 0.28426 -0.068599 0.65747 -0.029087 0.16184 0.073672 -0.30343 0.095733 -0.5286 -0.22898 0.064079 0.015218 0.34921 -0.4396 -0.43983 0.77515 -0.87767 -0.087504 0.39598 0.62362 -0.26211 -0.30539 -0.022964 0.30567 0.06766 0.15383 -0.11211 -0.09154 0.082562 0.16897 -0.032952 -0.28775 -0.2232 -0.090426 1.2407 -0.18244 -0.0075219 -0.041388 -0.011083 0.078186 0.38511 0.23334 0.14414 -0.0009107 -0.26388 -0.20481 0.10099 0.14076 0.28834 -0.045429 0.37247 0.13645 -0.67457 0.22786 0.12599 0.029091 0.030428 -0.13028 0.19408 0.49014 -0.39121 -0.075952 0.074731 0.18902 -0.16922 -0.26019 -0.039771 -0.24153 0.10875 0.30434 0.036009 1.4264 0.12759 -0.073811 -0.20418 0.0080016 0.15381 0.20223 0.28274 0.096206 -0.33634 0.50983 0.32625 -0.26535 0.374 -0.30388 -0.40033 -0.04291 -0.067897 -0.29332 0.10978 -0.045365 0.23222 -0.31134 -0.28983 -0.66687 0.53097 0.19461 0.3667 0.26185 -0.65187 0.10266 0.11363 -0.12953 -0.68246 -0.18751 0.1476 1.0765 -0.22908 -0.0093435 -0.20651 -0.35225 -0.2672 -0.0034307 0.25906 0.21759 0.66158 0.1218 0.19957 -0.20303 0.34474 -0.24328 0.13139 -0.0088767 0.33617 0.030591 0.25577\n",
            ", 0.17651 0.29208 -0.0020768 -0.37523 0.0049139 0.23979 -0.28893 -0.014643 -0.10993 0.15592 0.20627 0.47675 0.099907 -0.14058 0.21114 0.12126 -0.31831 -0.089433 -0.090553 -0.31962 0.21319 2.4844 -0.077521 -0.084279 0.20186 0.26084 -0.40411 -0.19127 0.24715 0.22394 -0.063437 0.20379 -0.18463 -0.088413 0.024169 -0.28769 -0.61246 -0.12683 -0.088273 0.18331 -0.53161 -0.1997 -0.26703 0.15312 -0.015239 -0.082844 0.47856 -0.29612 0.11168 -0.02579 -0.011697 0.19923 -0.14267 0.6625 -0.051739 -0.16938 -0.15635 0.092806 0.32548 0.11724 0.28788 -0.060651 -0.14153 0.16668 0.26861 -0.031001 -0.39665 0.35304 0.2385 0.12388 0.45698 -0.12559 -0.12804 0.37449 0.2446 0.23073 0.20808 0.051258 -0.21816 -0.036409 -0.0388 -0.042487 -0.30779 -0.025449 0.22532 0.045538 -0.48934 -0.13988 0.17394 -0.46137 -0.26555 0.15473 0.063816 -0.17022 -0.15762 0.075765 0.12151 -0.4934 -0.10909 0.034487 0.29947 0.01869 -0.16534 0.016679 0.16341 -0.27418 0.077797 1.4023 0.025275 0.094725 -0.040735 -0.10642 0.023364 0.079143 -0.16615 -0.23013 -0.14071 0.40159 -0.34951 0.018545 0.22434 0.76922 0.24722 0.14936 0.42368 -0.72059 -0.038541 0.15522 0.33596 -0.43077 -0.026925 -0.37733 0.24271 -0.46495 0.45783 0.23693 0.079361 -0.32244 -0.42434 -0.11138 0.55426 0.085153 -0.020581 -0.046386 1.2467 0.13177 0.067092 -0.5778 0.013586 -0.071274 0.017311 0.089781 0.19857 -0.032205 0.64843 -0.23797 -0.19676 0.20203 0.21074 -0.50347 0.026823 -0.045444 -0.22642 -0.19977 -0.12138 0.16941 0.061998 0.42631 -0.088383 0.45756 0.077774 0.061342 0.4571 -0.17787 -0.14597 0.32654 0.002443 -0.11886 0.10081 -0.020011 1.0366 -0.39814 -0.6818 0.23685 -0.20396 -0.17668 -0.31385 0.14834 -0.052187 0.0613 -0.32582 0.19153 -0.15469 -0.14679 0.046971 0.032325 -0.22006 -0.20774 -0.23189 -0.10814\n",
            ". 0.12289 0.58037 -0.069635 -0.50288 0.10503 0.39945 -0.38635 -0.084279 0.12219 0.080312 0.32337 0.47579 -0.038375 -0.00709 0.41524 0.32121 -0.21185 0.36144 -0.055623 -0.030512 0.42854 2.8547 -0.14623 -0.17557 0.31197 -0.13118 0.033298 0.13093 0.089889 -0.12417 0.0023396 -0.068954 -0.10754 -0.11551 -0.31052 -0.12097 -0.46691 -0.0836 -0.037664 -0.071779 -0.11899 -0.20381 -0.12424 0.46339 -0.19828 -0.0080365 0.53718 0.031739 0.34331 0.0079704 0.0048744 0.030592 -0.17615 0.82342 -0.13793 -0.10075 -0.12686 0.074735 -0.088719 -0.042719 0.076624 0.089263 0.064445 -0.031958 0.15254 -0.10384 0.076604 0.34099 0.24331 -0.10452 0.40714 -0.1826 -0.040667 0.50878 0.08076 0.22759 -0.042162 -0.18171 -0.095025 0.030334 0.088202 -3.9843e-06 -0.0039877 0.15724 0.33167 0.08471 -0.25919 -0.41384 0.2992 -0.54255 0.032129 0.1003 0.44202 0.044682 -0.090681 -0.10481 -0.1186 -0.31972 -0.2079 -0.040203 -0.022988 0.22824 0.0055238 0.12568 -0.1464 -0.14904 -0.11561 1.0517 -0.19498 0.083958 0.044812 -0.12965 -0.093468 0.21237 -0.088332 -0.1868 0.26521 0.13097 -0.048102 -0.22467 0.28412 0.34907 0.34833 0.017877 0.30504 -0.83453 0.048856 -0.1933 0.20764 -0.49701 -0.18747 -0.076801 0.15558 -0.46844 0.40944 0.21386 0.082392 -0.26491 -0.21224 -0.13293 0.14738 -0.14192 0.18994 -0.15587 1.0738 0.40789 -0.27452 -0.18431 0.00068679 -0.087115 0.19672 0.40918 -0.35462 -0.06326 0.4492 -0.060568 -0.041636 0.20531 0.017025 -0.58448 0.075441 0.082116 -0.46008 0.012393 -0.02531 0.14177 -0.092192 0.34505 -0.52136 0.57304 0.011973 0.033196 0.29672 -0.27899 0.19979 0.25666 0.082079 -0.078436 0.093719 0.24202 1.3495 -0.30434 -0.30936 0.42047 -0.079068 -0.14819 -0.089404 0.0668 0.22405 0.27226 -0.035236 0.17688 -0.0536 0.0070031 -0.033006 -0.080021 -0.24451 -0.039174 -0.16236 -0.096652\n",
            "of 0.052924 0.25427 0.31353 -0.35613 0.029629 0.51034 -0.10716 0.15195 0.057698 0.06149 0.06116 0.39911 -0.00029018 0.31978 0.43257 -0.14708 0.054842 0.27079 -0.14051 -0.30101 0.16313 3.0013 0.22231 -0.14279 0.083705 0.089866 -0.52706 -0.089661 0.27311 0.31413 -0.04081 0.060557 -0.042656 0.24178 -0.29187 0.22575 -0.6298 -0.14641 -0.22429 -0.056621 -0.17776 -0.64269 0.51626 0.22305 0.12124 0.48074 0.41743 0.54805 0.40955 0.42407 0.049906 -0.32574 0.46298 0.19245 0.28143 0.2966 0.063593 -0.11906 -0.15016 -0.04984 0.40675 0.010675 -0.69127 0.048729 0.26391 0.30961 -0.11921 0.25548 -0.28219 -0.037413 0.36461 0.027129 0.20786 0.53325 0.50148 0.72381 0.065292 -0.078716 -0.10537 -0.08081 -0.2096 0.040902 -0.88101 0.24715 0.16146 0.10361 0.19705 -0.27365 0.89902 -0.29981 0.036165 0.041238 0.60105 -0.18911 -0.43887 -0.14097 0.44073 -0.19999 0.28834 -0.25458 -0.10985 -0.0027379 0.091735 0.17021 -0.16305 -0.57439 0.37063 1.7262 -0.24656 0.51681 -0.15355 -0.15553 0.019783 0.1803 0.38178 0.094443 -0.55158 -0.20242 -0.4386 -0.42108 0.27525 0.58977 0.026655 0.16401 0.13893 -0.68692 0.51071 0.29278 0.022041 -0.18156 -0.64905 0.16923 -0.01059 0.21785 -0.27242 0.27967 0.1395 -0.70559 -0.26034 -0.44017 0.15303 0.19693 -0.096838 0.14827 1.1294 -0.31267 0.0099916 -0.48623 0.080584 0.35608 -0.19925 0.19306 -0.2004 -0.44194 0.75766 0.24487 -0.18903 0.26653 -0.21339 -0.54083 0.40532 -0.02796 -0.13398 -0.11086 0.059506 0.24052 -0.59739 -0.0024069 -0.18593 1.042 -0.12969 0.20813 0.33305 -0.1278 0.085662 -0.076422 0.31407 -0.23784 -0.054838 0.011369 0.845 -0.34165 0.093983 0.082445 -0.27777 -0.44226 -0.063078 0.37274 0.054468 0.24197 -0.040886 0.3894 -0.10509 0.23372 0.096027 -0.30324 0.24488 -0.086254 -0.41917 0.46496\n",
            "to 0.57346 0.5417 -0.23477 -0.3624 0.4037 0.11386 -0.44933 -0.30991 -0.0053411 0.58426 -0.025956 0.49393 -0.037209 -0.28428 0.097696 -0.48907 0.026027 0.37649 0.057788 -0.46807 0.081288 3.2825 -0.6369 0.37956 0.0038167 0.093607 -0.12855 0.1738 0.10522 0.28648 0.21089 -0.47076 0.027733 -0.19803 0.076328 -0.84629 -0.79708 -0.38743 -0.030422 -0.26849 0.48585 0.12895 0.38354 0.38722 -0.38524 0.19075 0.48998 0.13278 0.010792 0.2677 0.17812 -0.11433 -0.33494 0.87306 0.75875 -0.30378 -0.15626 0.0012085 0.23322 0.27953 -0.18494 -0.14146 -0.18969 -0.038386 0.35874 0.065513 0.060565 0.66339 -0.083252 0.065163 0.51761 0.16171 0.46011 0.16388 -0.12399 0.31122 -0.15412 -0.10917 -0.42551 0.11418 0.25137 -0.056158 -0.25927 0.28163 -0.018094 0.16065 -0.48506 -0.98903 0.25022 -0.16736 0.41474 0.17701 0.42407 0.11088 -0.1836 -0.1241 -0.3478 0.099078 -0.22381 -0.11245 -0.21156 0.0030706 -0.23607 0.027261 0.3643 0.039922 -0.18369 1.2266 -0.7764 -0.66225 0.015724 -0.14969 0.084649 0.26814 -0.16765 -0.31942 0.28494 -0.07 0.01201 -0.12219 0.5631 -0.32 0.50109 -0.10209 0.46575 -0.71542 0.17293 0.58259 0.078384 -0.033844 -0.25129 0.36503 0.031578 -0.65778 0.05475 0.87189 0.12455 -0.45877 -0.26965 -0.46779 -0.0028578 0.1781 0.63969 0.13995 0.97596 0.11836 -0.63904 -0.15416 0.065262 0.24329 0.66476 0.25069 -0.10252 -0.32839 -0.085559 -0.012774 -0.19431 0.56139 -0.35733 -0.20344 -0.12413 -0.34431 -0.23296 -0.21187 0.085387 0.070063 -0.19803 -0.026023 -0.39037 0.80002 0.40577 -0.079863 0.35263 -0.34043 0.39676 0.22862 -0.35028 -0.47344 0.59742 -0.11657 1.0552 -0.4157 -0.080552 -0.056571 -0.16622 0.19274 -0.095175 -0.20781 0.1562 0.050231 -0.27915 0.43742 -0.31237 0.13194 -0.33278 0.18877 -0.23422 0.54418 -0.23069 0.34947\n",
            "and 0.20327 0.47348 0.050877 0.002103 0.060547 0.33066 0.048486 0.021504 -0.53631 0.21312 0.19983 0.51408 0.00070422 0.094641 0.068724 0.27424 -0.20493 0.23268 0.3249 -0.19444 0.64693 2.8342 0.14004 -0.26868 0.27325 0.015312 -0.27975 -0.26423 0.14183 -0.026064 0.11349 0.25039 -0.24972 -0.16882 -0.31039 -0.44458 -0.34789 -0.20181 -0.013405 0.23635 0.17741 -0.10535 -0.20716 0.37856 0.10507 -0.3097 0.46782 -0.50021 0.26643 0.51564 0.054247 0.50546 -0.24959 0.54021 0.17268 -0.03865 0.02373 0.24111 0.1721 0.078734 0.31275 0.187 -0.45933 0.55853 0.22511 0.16761 -0.045662 0.55918 -0.24065 -0.24904 0.38718 -0.21586 -0.10332 0.24157 -0.1844 0.31295 -0.16315 -0.21771 0.18137 -0.045089 0.068367 -0.17317 -0.79639 0.24492 0.12389 0.11703 -0.088345 -0.37042 0.43759 -0.47564 -0.095386 -0.15975 0.1838 0.25664 -0.41276 0.047558 0.16437 -0.26353 -0.27328 -0.089788 0.31598 -0.11246 -0.18703 0.20422 0.068352 0.011667 0.13657 1.1524 0.024065 -0.11591 -0.18142 -0.36441 -0.010051 0.19956 0.2685 -0.095357 -0.11906 0.32378 -0.19527 -0.368 -0.0038172 0.396 0.24194 0.31296 0.24128 -0.7612 0.071389 0.42396 0.26369 -0.091366 -0.13438 -0.17673 0.013168 -0.624 0.17744 0.38957 -0.037665 -0.12586 -0.14862 -0.29635 0.40572 -0.071653 -0.11642 -0.16958 1.0982 0.39618 -0.16874 -0.6036 0.41394 0.28977 0.11419 -0.047337 -0.0033519 -0.42435 0.61701 -0.01048 -0.28841 0.42077 -0.075991 -0.38083 0.57339 0.18044 -0.11781 0.35162 0.1622 0.55483 0.14 0.2321 -0.20205 0.60227 -0.15379 0.21907 0.28405 0.011906 0.10622 0.5067 -0.43201 -0.40887 -0.17819 0.22042 1.0775 -0.39381 -0.35828 0.36302 0.14872 0.035555 -0.030339 -0.11273 0.023382 0.15904 -0.14389 -0.11754 -0.63655 -0.12197 0.043809 0.14716 0.07375 -0.21358 -0.62249 0.14386\n",
            "in -0.10272 0.3041 -0.13577 -0.27979 -0.40926 -0.26553 0.10492 -0.044101 0.062731 -0.0416 0.35588 0.40757 -0.14295 -0.036534 0.42512 0.014823 0.00030443 0.2915 -0.20416 -0.10039 0.30767 3.1815 0.045614 0.094457 0.25545 0.27528 -0.29939 0.045123 0.44681 0.015012 -0.10785 -0.38988 -0.20562 0.26306 -0.018163 -0.14244 -0.5661 -0.12168 0.28749 -0.30581 -0.4482 -0.15317 -0.19445 0.35335 -0.015209 0.23061 0.13566 -0.26385 0.066084 0.16075 0.12168 0.72758 0.32453 0.82149 -0.13693 -0.2006 -0.097958 -0.15446 -0.38003 0.15699 0.041498 -0.22766 -0.40033 0.25514 0.13092 0.24261 -0.48639 -0.27622 -0.21293 -0.11668 0.014564 0.21658 0.19006 0.40863 0.48486 0.4037 0.20366 -0.096563 0.19522 -0.16715 -0.31923 -0.35499 -0.34792 0.59981 -0.046506 -0.27371 0.013404 -0.36558 0.69315 -0.2407 -0.0137 0.22596 0.21897 0.010207 -0.23484 -0.36304 0.1029 -0.4278 0.28864 -0.43645 -0.083785 0.1183 0.20385 0.40474 -0.079155 -0.12931 0.077845 1.2303 -0.55546 0.1562 0.0063933 -0.46652 0.013173 0.52646 -0.23626 0.013833 0.10002 0.090947 -0.25318 -0.64795 0.063422 0.74095 0.2902 0.22642 0.33915 -0.80488 0.21889 0.19193 0.05539 -0.39976 0.0094308 0.26978 0.63166 -0.41242 0.20485 0.33116 0.11562 -0.45671 -0.48083 0.46172 0.27319 0.243 0.12328 0.2307 1.2257 0.037079 0.23077 -0.31092 -0.099628 0.41876 -0.093834 -0.24741 -0.49863 -0.74542 0.16518 0.069734 0.066691 -0.092037 0.21124 -0.28236 0.20825 -0.17163 -0.32025 -0.27537 -0.30774 0.18184 -0.02626 -0.062733 -0.43666 0.57954 -0.32348 -0.13457 0.38565 -0.30198 0.26197 -0.10034 -0.146 -0.3417 0.16671 -0.23599 1.2467 -0.0059839 -0.56967 0.5264 -0.21024 -0.29861 -0.293 0.15889 0.17254 -0.0023984 0.071749 0.053166 -0.23429 -0.084927 0.15539 0.4182 -0.15216 0.36951 0.19039 -0.12266\n",
            "a 0.24169 -0.34534 -0.22307 -1.2907 0.25285 -0.55128 -0.080336 -0.0081767 0.31136 -0.45101 0.24661 0.36441 0.94336 -0.03542 0.78048 -0.39765 0.31125 -0.17743 -0.41989 -0.37815 0.6723 3.1716 0.032496 -0.03164 0.58068 -0.44458 -0.055612 0.18052 0.28572 0.09587 0.21437 0.049731 0.1872 0.11914 0.027408 -0.80608 -0.30835 -0.89737 -0.19772 0.026741 -0.38765 0.11659 -0.2011 0.20101 -0.079133 -0.050954 0.0060189 0.3347 -0.21118 0.074042 -0.28141 -0.059615 -0.35296 0.64748 0.053908 -0.31376 -0.36622 -0.27755 0.022676 0.048811 0.14312 -0.1858 -0.56964 -0.54119 0.18616 0.18854 0.27521 -0.17835 -0.37438 0.12109 0.001861 -0.0092127 0.10186 0.098081 -0.37245 0.66415 0.057366 -0.43845 -0.40525 -0.55959 -0.11343 -0.54987 -0.26321 -0.28471 0.14411 0.1036 -0.32198 -0.2153 0.98668 -0.41937 0.3119 0.3338 0.16018 0.33137 -0.025494 -0.03788 -0.12048 -0.12175 0.094766 0.26158 0.029931 -0.29625 0.43401 -0.036536 -0.42852 -0.39638 -0.24973 1.1018 -0.22812 0.24324 0.083857 -0.48881 -0.21316 0.040249 -0.40516 -0.12411 -0.19728 -0.73696 -0.44582 -0.44992 -0.073707 -0.16454 0.16011 -0.41952 0.41417 -0.57277 0.51367 0.081118 0.029288 0.35309 -0.10803 0.13702 0.38828 -0.28813 0.68203 0.17412 -0.08854 -0.29785 -0.28455 0.1357 0.15232 0.22037 0.68812 -0.131 1.8197 -0.45153 0.39553 -0.60817 0.33698 0.1109 -0.28476 0.30461 -0.21606 -0.058111 0.44172 -0.24231 -0.12758 -0.048793 -0.15495 -0.85491 0.092912 -0.060809 0.029073 -0.38735 -0.070853 -0.65975 -0.38157 0.5017 -0.7356 0.41521 0.21328 -0.33779 0.66902 0.42486 -0.12148 -0.010626 0.12745 -0.13561 0.23423 0.3511 1.2841 0.12982 0.21357 0.32857 0.16567 -0.21458 -0.44275 0.3285 0.18001 0.064865 -0.3588 -0.014226 0.31125 -0.22049 0.032829 0.38525 -0.10512 0.27801 -0.10171 -0.071521\n",
            "\" 0.0010318 0.31201 -0.59768 -0.12583 -0.27524 0.29145 -0.30431 0.037122 0.94468 0.088085 -0.096273 0.40542 -0.6524 0.37716 0.53001 -0.30819 -0.27478 0.81041 0.53635 0.08759 0.35288 2.8857 -0.12505 -0.035968 0.1355 -0.29932 0.56154 -0.59429 -0.34991 0.68559 -0.11537 0.088894 -0.29829 -0.20768 0.6911 0.068548 -0.50814 -0.97722 0.035782 -0.54053 -0.16178 0.47542 -0.71652 0.31939 -0.049291 0.32565 0.5551 -0.42967 1.0137 0.30304 0.44503 0.46987 0.074292 -0.35762 -0.13736 -0.16066 -0.28606 0.00012358 -0.043422 -0.36702 0.40895 -0.40467 -0.51635 0.28044 -0.27625 -0.20352 0.084837 0.078145 0.32895 0.20482 0.17551 -0.2309 -0.066328 0.46467 -0.38932 -0.23018 -0.098122 -0.12376 -0.028503 0.040342 0.71158 -0.27804 0.10137 0.51113 -0.42648 -0.12535 -0.39139 0.29972 0.1868 -0.58113 0.38192 0.1654 0.33566 -0.47696 -0.24135 -0.33114 0.34815 -0.087061 -0.16406 -0.1023 0.53301 0.45604 0.33281 -0.33851 0.30248 -0.15048 -0.33033 0.6668 -0.28609 1.0374 -0.70909 -0.084268 0.47584 -0.16125 0.19906 0.51991 0.026676 -0.25567 -0.32363 0.13236 0.54006 0.093419 0.12268 -0.62967 0.00074921 -0.53441 0.25609 0.39963 0.80527 -0.41176 0.18955 0.024526 -0.20222 0.33781 0.007872 -0.64424 -0.5309 0.027875 0.088964 0.29687 -0.038186 0.77967 -0.069213 -0.58387 1.1816 0.60791 -0.4021 -0.32223 -0.071283 -0.022764 -0.46393 0.99797 -0.15308 0.4712 0.73921 -0.12487 -0.38275 -0.39598 0.12852 -0.4951 0.19752 -0.25436 0.16616 -0.18135 0.16374 -0.16194 -0.32013 -0.33111 0.53662 0.53301 -0.32166 -0.64362 1.0576 -0.18019 -0.40932 -0.16084 -1.0094 0.22972 0.5431 0.05891 1.7502 -0.19753 -0.05401 0.016083 -0.55523 -0.20231 -0.32613 -0.38783 0.61428 -0.11216 0.42319 -0.44729 -0.35638 -0.32698 -0.12662 -0.28858 0.08092 0.14493 0.052563 0.75007\n",
            "'s -0.0059614 0.45148 0.0045495 0.020727 0.53877 0.49453 -0.35369 -0.056286 0.057851 -0.2045 -0.3064 0.37904 0.26388 0.36036 0.68715 0.11629 -0.57005 0.084364 -0.67184 0.21706 0.60084 3.1461 0.21839 0.1883 -0.011606 0.7028 -0.054734 -0.57602 -0.50561 0.13275 -0.37349 -0.22315 0.18934 -0.38835 -0.44616 0.25078 -0.24067 -0.27303 -0.63587 0.071991 -0.30948 -0.65413 -0.075834 0.40565 -0.28402 0.44169 -0.22619 0.10845 -0.015489 -0.30989 -0.02178 -0.11869 0.17083 -0.099277 0.30043 0.18093 -0.25603 0.084124 0.052387 0.61726 0.214 -0.22772 -0.87764 -0.14982 -0.23043 -0.00035754 -0.32101 0.027185 0.21575 0.36466 0.6246 -0.12043 0.05141 0.91292 0.18761 0.93069 -0.35316 -0.17359 -0.29801 -0.47032 -0.30814 -0.030579 0.0010451 -0.4248 0.025234 0.10384 -0.48836 -0.052485 0.40014 -0.7495 -0.13414 0.4474 -0.29949 0.09747 -0.55787 0.20784 0.07845 -0.018413 0.51101 -0.081727 -0.12922 0.26656 0.019702 0.32468 -0.0065269 -0.61234 0.16835 1.4625 -0.69953 -0.4955 -0.14897 -0.31528 -0.84419 0.015958 -0.32832 0.17431 -0.17892 0.19392 -0.18366 0.025364 0.26547 0.44295 0.38296 -0.087653 0.72418 -0.48724 0.014929 -0.2459 -0.026036 0.13949 0.12917 -0.29052 0.24795 -0.74504 -0.12584 0.66134 0.14745 0.020824 -0.17371 -0.10235 -0.38495 0.85243 0.34448 0.46187 1.2913 0.085984 -0.13995 -0.77678 0.33022 0.4462 0.4717 0.11727 0.61142 0.39587 0.34127 -0.084882 -0.18584 0.076045 -0.33183 0.052621 0.66403 -0.19629 -0.066911 0.20812 0.29366 0.3302 -0.21909 -0.27987 0.11026 0.47563 0.49742 0.071567 0.19419 -0.13688 -0.069569 0.49701 -0.84327 -0.44757 0.50253 0.60596 0.86543 0.47559 -0.0093512 0.00081187 -0.59952 -0.12317 -0.30361 0.17132 0.82369 0.2679 0.33455 0.35521 -0.56247 0.37289 0.51554 -0.0036403 0.076358 0.39947 0.29621 0.053627\n",
            "for 0.29117 0.86093 -0.66616 -0.13595 0.057122 -0.041478 -0.1934 0.046968 -0.1983 0.37853 0.31329 0.51347 0.18066 0.24203 0.54115 0.12255 0.032923 0.36946 0.050416 -0.15927 0.36775 3.4054 -0.25448 -0.002363 0.080148 0.05471 -0.035962 -0.14028 0.31055 0.43488 0.14837 -0.094012 -0.005442 0.093375 0.037874 -0.66711 -0.28365 -0.42911 -0.48537 0.26096 -0.02938 -0.26486 0.064483 -0.045022 0.17783 0.084124 0.37788 0.28682 0.11652 0.46445 -0.28041 -0.082759 -0.1779 1.0684 0.082103 -0.25152 -0.14532 0.1425 -0.034477 -0.0097871 0.023049 -0.34823 -0.72543 0.13475 0.38666 -0.0019374 0.30354 0.24929 -0.092021 0.17877 0.38102 -0.032314 0.41566 -0.024924 0.10488 0.79847 -0.22442 -0.42577 0.26706 -0.33512 -0.0046086 -0.25252 0.06349 0.13295 0.24894 -0.2511 -0.46083 -0.4154 0.53157 -0.70003 0.13744 -0.34552 0.23247 -0.10948 0.011912 -0.26473 0.1713 -0.11878 -0.29592 0.36057 -0.016674 -0.21369 0.028695 0.38667 -0.2356 0.070287 0.31011 1.3284 -0.26647 -0.37752 -0.087182 -0.64794 0.044101 0.15345 -0.59556 -0.068393 0.28695 -0.04261 -0.51398 -0.5981 -0.0091412 -0.42449 0.52921 0.57187 0.084888 -0.69688 -0.1245 -0.17993 0.023413 -0.11261 -0.42252 0.07884 0.64789 -0.36234 0.3205 0.4371 0.26627 -0.27574 -0.091605 0.14883 -0.07072 -0.34668 0.12508 -0.018001 0.94311 0.15681 -0.214 0.11468 -0.024933 0.046819 -0.2587 0.35997 -0.23112 -0.20346 0.62286 -0.32509 -0.016273 0.21298 -0.034612 -0.25255 -0.0023635 0.32627 -0.094363 0.10246 -0.17472 -0.16649 -0.26687 -0.080157 -0.073246 0.81884 0.03966 0.061979 0.66284 -0.096086 0.08781 -0.0088198 -0.57192 -0.21585 -0.026997 0.30988 1.0213 -0.609 -0.059565 -0.2802 -0.25692 0.083446 -0.35978 0.10253 -0.2064 -0.0064343 -0.037507 0.45306 -0.17545 0.34726 0.39375 -0.15266 -0.35208 -0.072196 0.11047 0.041999\n",
            "- -0.52482 -0.31963 -0.11898 -0.62672 0.043607 0.039176 -0.74566 -0.29516 -0.70795 0.50644 -0.12069 0.6046 0.17881 -0.32358 0.6784 0.61368 -0.6822 -0.90958 -0.35056 -0.50691 0.42474 3.3311 -0.29048 0.31487 0.298 0.30849 -0.59682 -0.090485 0.63417 0.11428 0.60949 0.4275 -0.022331 0.81869 -0.2009 0.40097 0.018467 -0.32795 -0.38703 0.89553 0.17345 -0.20786 0.19661 0.33308 -0.59757 -0.025713 0.54123 -0.59299 0.043237 -0.43826 0.13732 0.074199 0.20826 0.079075 0.36866 -0.10027 -0.5015 -0.099859 0.36711 0.49379 0.17505 0.094238 -0.84836 -0.049805 -0.55745 -0.60496 -0.13797 -0.94929 1.0498 -0.070823 0.45472 0.14697 0.098133 0.50213 0.46113 0.86423 -1.0124 -1.102 0.19509 -0.077223 0.62998 -1.1331 -0.36886 -0.87241 0.005532 0.096174 0.96655 0.1061 0.56135 -1.3818 0.80819 -0.20846 0.4186 0.099999 -0.66175 0.28933 -0.89051 0.037495 0.046292 -0.39863 0.24835 -0.21226 0.6419 0.77302 1.2258 -0.72872 -0.78351 1.6679 -0.35259 -0.40263 0.10265 -0.24384 -0.33026 0.0053107 -0.47305 -0.0041587 0.29857 0.021387 -0.65835 -0.01013 -0.78507 0.0074187 0.47464 0.86598 0.72612 -0.93103 0.28582 -0.51885 0.85647 -0.10641 -0.27125 -0.29949 0.23144 -0.37855 0.1695 -0.13784 0.36443 -0.645 -0.32647 0.16657 -0.030835 -0.49339 -0.72254 0.10345 1.101 -0.83535 0.075303 -0.038513 -0.01167 0.348 -0.090702 0.079266 -0.24702 -0.14607 -0.42316 0.049463 -0.17431 0.41349 -0.43356 -0.65549 -0.31301 0.1172 -0.14051 -0.29881 0.20175 -0.51763 0.002963 0.52113 -0.10565 0.11865 0.25795 -0.27689 0.69176 -0.03288 -0.077013 -0.16738 -1.3355 -0.71185 -0.76961 0.49021 0.66794 -0.11177 0.090625 0.46741 0.8878 -0.13181 -1.5339 1.1401 0.80685 -0.080188 -0.8708 -0.52954 0.41509 0.31474 -0.23211 0.4655 0.34637 -0.046424 0.58811 1.5755\n",
            "that 0.14805 0.10875 -0.036278 -0.15386 0.37181 0.293 -0.7026 0.00095636 0.24551 0.034012 0.034138 0.64364 -0.012599 0.024661 0.16286 0.077917 -0.31525 0.72081 -0.51842 -0.255 0.48959 3.1749 -0.37991 -0.03827 0.04576 0.06793 -0.11716 -0.3341 -0.10723 -0.23873 -0.4576 -0.024502 0.14723 -0.13546 0.089812 -0.38768 -0.95797 -0.62072 -0.11763 0.21322 0.080894 -0.25967 -0.093584 0.52106 -0.11793 0.21224 0.45115 -0.063134 -0.21954 -0.027564 0.01874 -0.35228 -0.23418 0.17759 0.19368 -0.20396 -0.11582 -0.19091 0.11507 0.13767 0.083718 0.17958 -0.22568 0.0061614 0.15113 -0.17524 -0.23794 0.21519 -0.087514 0.30629 0.41841 0.2913 -0.04346 0.204 -0.073017 0.38145 -0.14291 -0.17308 -0.3977 -0.2886 -0.028762 0.020877 -0.11252 0.31002 0.17208 0.11718 -0.72813 -0.27098 0.35079 -1.1096 0.71817 0.30775 0.53219 0.062995 -0.50855 0.41816 0.29686 0.062927 0.043386 -0.32052 0.14399 0.2765 -0.02649 0.077377 0.057718 -0.089084 0.06331 1.1641 -0.44109 -0.28368 0.26062 -0.48025 0.04018 -0.13092 0.42519 0.15305 -0.26543 -0.25001 -0.34873 0.13545 0.28868 0.56992 0.23826 0.29515 0.11743 -0.41814 0.35357 0.059823 0.37723 0.096062 -0.18146 0.19874 0.20747 -0.24454 0.31293 0.28901 0.079401 -0.28556 -0.031735 -0.043442 0.021977 0.25087 0.18158 -0.31774 1.6057 0.34543 -0.019671 -0.62405 0.17909 0.1502 -0.0012357 0.27507 -0.030791 0.38623 0.23872 -0.59215 -0.23935 0.338 0.19547 -0.1736 -0.22177 0.12624 0.13052 -0.16421 0.0092456 0.19234 -0.055088 0.1565 -0.28712 0.53327 0.45624 0.40083 0.36637 0.14608 -0.13729 -0.15897 -0.39163 0.094353 0.13397 0.095591 1.4247 -0.263 -0.15679 0.043102 -0.11161 0.11686 -0.32476 0.21426 0.44216 0.36477 0.10703 0.23798 -0.14344 0.27233 0.17654 -0.17613 0.05481 0.48022 -0.086013 -0.21791\n",
            "on -0.39374 0.55684 -0.35848 -0.67074 0.073665 0.12643 -0.013077 -0.2528 -0.04863 0.087937 -0.20308 0.43673 0.18453 -0.027372 0.18987 0.23822 -0.092781 0.31736 0.15368 0.14471 0.37138 3.1541 0.13773 0.0037497 0.14195 0.40222 -0.56691 0.17663 -0.3706 0.19401 0.074044 -0.19639 0.093499 0.78949 0.10651 -0.54262 -0.82392 -0.59019 -0.0074686 0.048896 0.26595 -0.071857 0.28968 0.46733 0.17435 0.65547 0.069246 -0.78889 0.20286 0.44911 -0.54471 0.10789 0.040975 0.60116 -0.14781 -0.21917 0.16495 0.40391 0.33915 0.3681 0.034313 -0.19928 -0.40278 -0.15649 0.010548 -0.27677 0.066898 -0.16746 0.1288 -0.11875 0.13574 -0.13967 -0.1601 0.20059 0.042929 0.343 0.027023 -0.26838 0.096476 0.05495 -0.20767 -0.52867 -0.32011 -0.089352 0.21718 0.44339 -0.27825 -0.51584 0.37681 -0.64233 0.12781 0.10471 0.41378 -0.01029 -0.1176 -0.20697 0.26689 -0.72601 0.19996 -0.81837 -0.10311 -0.23001 0.10628 0.096303 -0.16858 0.055709 0.068835 1.078 0.064561 -0.1824 -0.32465 -0.55668 -0.073582 0.071703 0.10335 -0.19905 -0.070396 -0.19203 -0.08814 -0.50102 -0.033088 -0.26299 0.0314 -0.11619 0.34837 -0.54018 0.093709 0.13945 0.11599 -0.28646 -0.33548 -0.033986 0.55028 -0.53672 -0.074195 0.36023 0.18919 -0.5318 -0.030495 0.51906 0.15201 -0.10314 -0.14523 -0.018952 1.4712 0.35201 -0.022265 -0.38351 -0.23719 0.10311 0.3934 0.65688 -0.052513 0.26787 0.21899 -0.17744 0.16229 0.27534 -0.15967 -1.0021 0.36849 0.23651 -0.59118 -0.21634 0.43708 -0.29897 -0.051803 0.20617 -0.23085 0.92028 0.083998 0.0087679 0.60472 -0.49388 -0.22373 0.30978 -0.76333 -0.318 0.27995 -0.24469 0.94786 -0.19595 -0.054997 -0.13711 -0.17249 0.22193 0.068174 -0.46008 0.25302 0.31222 0.45567 0.26039 -0.6393 0.55483 0.17156 0.0092464 -0.24973 -0.33932 0.032222 0.3259\n",
            "is 0.32928 0.25526 0.26753 -0.084809 0.29764 0.062339 -0.15475 0.17784 0.32328 -0.92752 0.15194 0.16324 -0.10428 -0.026464 0.65971 0.14782 0.38623 0.25169 0.1261 -0.43138 0.28092 3.1604 -0.17565 -0.0032247 0.64389 -0.39697 0.18975 0.37999 -0.079175 -0.14781 -0.072965 0.057247 -0.42314 0.4508 -0.097386 -0.47587 -0.96599 -0.75595 -0.033932 -0.070886 -0.44828 -0.52094 -0.1823 0.18582 -0.074273 -0.017871 0.16742 0.015459 0.3029 -0.1258 0.32418 -0.31263 -0.076832 0.051959 0.27242 -0.18285 -0.36479 -0.63562 -0.21685 0.035812 0.12485 0.37268 -0.16976 -0.094146 -0.16412 -0.10728 0.037866 0.1175 -0.15533 0.34062 0.58848 0.38992 -0.54839 0.85013 -0.83728 0.15482 -0.37191 -0.65409 -0.27631 -0.025224 0.075732 -0.23904 -0.18311 -0.084571 0.15492 -0.16317 -0.26499 0.056831 0.88287 -0.47655 0.25131 -0.09316 0.34377 -0.35863 -0.22855 0.11918 0.29661 -0.2536 0.049002 -0.21234 0.16237 0.53871 0.035344 0.39293 -0.29673 -0.72556 -0.27431 1.3469 -0.19218 0.50534 0.028451 -0.32206 0.096035 -0.0083551 -0.013107 -0.32444 -0.10163 0.031755 -0.63196 -0.21541 -0.035609 0.31259 0.23988 -0.19056 -0.13086 -0.12644 0.48795 -0.13492 -0.41967 0.15904 -0.27921 -0.017258 0.2937 0.067436 0.085052 0.099394 -0.0055281 0.094985 0.11167 0.19749 0.2523 0.32205 0.42778 -0.03518 1.3291 0.005261 0.26769 -0.46168 0.1125 0.10111 -0.31174 0.5458 -0.37363 -0.026133 0.99566 -0.15827 -0.26202 0.17324 0.060104 -0.48004 0.23841 -0.21495 0.077693 -0.089078 0.12985 -0.174 -0.057151 0.48207 -0.14668 0.26739 -0.33366 0.32552 0.6252 -0.30905 0.087737 -0.17204 0.28246 -0.037268 0.16007 0.30031 1.4061 -0.32169 -0.025792 0.037175 0.026222 -0.27671 0.051688 -0.058734 -0.23223 -0.10529 -0.40318 -0.22161 0.060587 0.091321 -0.21363 0.071634 -0.21331 0.074621 0.012001 -0.21952\n",
            "was -0.1996 -0.27529 -0.21257 -0.71516 -0.1549 0.04744 -0.32025 -0.4294 0.84117 -0.45861 0.46876 -0.054149 0.22078 0.0084582 0.45811 0.30798 -0.073609 0.35898 0.82944 -0.51263 0.30317 2.9621 -0.0031413 -0.053131 -0.35959 -0.068231 -0.35735 -0.096543 0.13234 0.12815 -0.1523 0.24723 0.12151 -0.10854 -0.23738 -0.21942 -0.70251 -0.8223 -0.15707 -0.11346 -0.35851 -0.56405 -0.40362 0.16661 -0.19537 -0.01106 0.16111 0.4828 0.082268 0.14569 -0.22031 0.18292 0.14894 0.37657 -0.38771 -0.17916 -0.31672 -0.089953 -0.67458 -0.51751 -0.33057 -0.16639 -0.58417 0.10553 0.44919 -0.31165 -0.5539 0.014905 -0.17927 0.21399 0.24111 -0.55032 0.24999 0.40902 -0.34321 -0.28075 -0.040672 -0.25232 0.072759 -0.20593 0.40777 -0.52954 -0.18148 0.30047 0.28422 0.31004 -0.23554 -0.52307 0.19999 -0.20385 -0.078657 -0.014303 0.43278 -0.0097031 -0.54804 0.04371 -0.20228 -0.29501 -0.035128 -0.011329 -0.17056 -0.46978 0.31591 0.10943 -0.21365 -0.61178 0.082581 0.63293 -0.37207 0.045178 0.016065 -0.065003 -0.38396 0.074427 0.27676 0.039811 -0.45756 -0.30758 -0.12329 -0.40815 -0.095112 -0.045512 0.49177 -0.057981 0.53833 -0.5234 0.057365 0.12221 -0.21479 -0.64182 0.19591 -0.40197 0.43444 -0.24733 0.57225 0.61664 -0.32289 0.3253 -0.50561 0.25248 -0.25128 0.039619 -0.0086546 -0.55293 1.6799 0.13093 -0.059073 -0.60842 0.44834 0.035975 -0.14268 0.22482 -0.092467 -0.16819 0.10019 0.045576 -0.31935 0.49191 -0.011527 -0.55505 0.11389 0.090062 0.11485 0.31311 -0.38175 0.22494 0.13168 0.30068 -0.65599 0.44653 0.44571 0.22652 0.63058 -0.59117 0.32318 -0.13474 -0.059211 -0.17087 0.18217 0.29661 1.2305 0.34507 -0.21769 -0.070667 -0.77584 -0.45988 -0.31078 0.13432 0.23961 0.21488 0.12674 -0.12343 -0.43656 -0.057027 0.39743 0.36176 -0.39222 -0.26509 -0.14119 0.013857\n",
            "said -0.13569 0.14029 0.0041988 -0.32062 0.012745 0.92511 -0.44523 -0.16454 0.6016 0.4267 0.26053 0.71426 0.57701 -0.09754 0.64286 -0.0002438 -0.3013 0.097057 -0.21678 -0.27131 0.30927 3.0062 -0.3179 0.28998 -0.39905 0.11234 0.19019 -0.49873 0.11857 -0.22241 -0.52668 -0.040781 -0.16783 -0.35887 0.60394 -0.069027 -0.60611 -0.22444 -0.51665 0.77766 -0.41533 -0.23924 -0.64725 0.16413 -0.41185 -0.15507 0.52085 -0.29298 0.034067 -0.71414 0.17124 0.18186 -0.62824 -0.21882 -0.3784 -0.60484 -0.10613 -0.0065723 0.52873 -0.12537 1.1519 0.16512 -0.12301 0.73452 0.15381 -0.021303 -0.4185 0.32132 -0.56697 0.58886 -0.19564 -0.1671 0.35969 0.42898 -0.071104 0.50165 0.15248 -0.089535 -0.67192 0.1817 -0.030661 -0.20289 -0.23925 0.33899 0.088455 -0.16614 -0.78902 0.14403 -0.22256 -1.377 0.38399 -0.14929 -0.16867 -0.73194 -0.76784 0.96968 0.26804 0.36036 -0.33896 -0.17303 0.3866 -0.76154 -0.52335 0.091027 0.049086 0.059747 0.13165 1.9048 -0.77324 -0.094455 0.17805 -0.096256 0.0684 -0.36729 0.011347 0.12147 0.2453 -0.4354 -0.1733 0.36181 0.78902 0.66458 0.45523 0.079105 0.30238 -0.29991 -0.25161 -0.060112 0.59835 -5.4345e-06 0.47396 -0.25035 -0.16549 0.54022 0.62029 0.43227 0.44656 -0.45033 -0.22726 -0.060223 0.42781 0.34668 -0.38491 -0.25167 1.0969 0.66604 0.036542 -0.32485 0.4289 0.13762 -0.22326 0.69871 0.23841 0.89013 0.23899 -0.51714 -0.050005 0.1487 0.055402 -0.41163 -0.33454 -0.014032 0.36476 -0.23411 -0.13272 -0.050314 0.19593 0.16193 0.28734 0.13478 0.74715 -0.060806 0.14221 0.047109 -0.44866 -0.408 -0.68475 -0.25236 0.16233 -0.33454 0.69021 -0.36958 -0.4338 -0.099908 -0.53847 -0.16861 -0.54684 0.40052 0.11458 0.45688 0.28415 0.43329 0.11012 0.22958 0.024016 0.20695 0.23759 0.0087948 -0.13017 -0.25626\n",
            "with 0.10353 0.07205 -0.029303 -0.4468 -0.086126 0.074003 -0.4655 -0.061857 -0.50365 0.19548 -0.10335 0.77593 -0.17204 -0.45352 0.26304 0.16434 0.28028 0.28933 0.31036 0.012775 0.67952 2.6277 0.38964 -0.4499 0.21797 0.09164 -0.16794 0.077242 0.29127 0.12053 -0.054966 0.09166 0.1313 -0.093327 -0.35301 -0.50388 -0.7298 -0.36138 -0.29966 0.020784 -0.07036 -0.067227 -0.036265 -0.014601 -0.059858 -0.16302 0.30066 -0.092812 -0.06698 0.14383 0.10395 -0.019304 -0.40702 0.88675 0.26735 -0.12383 0.027374 0.34464 0.60405 0.28064 0.14132 0.24643 -0.44876 0.54291 0.19676 -0.49471 0.026878 0.2691 0.25341 0.098868 0.17792 -0.32229 -0.10593 0.18952 -0.25763 0.24362 -0.24556 -0.13654 -0.10817 -0.42122 -0.16164 -0.3412 -0.14739 -0.21641 -0.05624 0.71588 0.064057 -0.30779 0.65737 -0.63691 0.26404 0.21506 0.18385 0.33261 -0.063022 -0.22245 0.063198 -0.44795 -0.25228 0.1977 -0.35548 0.11914 -0.29915 0.12939 -0.43077 -0.1377 0.23843 1.4553 -0.11371 -0.37979 -0.28313 -0.46482 -0.19276 0.019849 0.27009 -0.17085 -0.05201 -0.20322 -0.32744 -0.50757 0.029829 0.18035 0.30533 0.2407 0.46612 -0.71253 0.59672 0.21331 0.34864 0.38019 0.13826 -0.073338 0.22635 -0.4556 0.0081981 0.34732 -0.13608 -0.65982 -0.27943 0.04818 -0.039713 0.28645 0.14126 -0.03943 1.4452 0.45995 0.079285 -0.35558 0.030936 -0.025081 0.056487 0.090076 0.052031 -0.39953 0.34033 -0.4174 -0.38219 0.22205 0.10952 -0.16454 0.12061 0.16092 -0.32746 0.2458 -0.022832 0.27411 -0.021069 0.39146 -0.56102 0.69551 -0.035526 0.047164 0.67191 0.48124 -0.027884 0.50549 -0.54186 -0.35237 -0.31201 -0.0017602 0.95944 -0.50364 0.43989 0.47181 0.4258 -0.59221 -0.39622 0.018904 0.033382 -0.29015 -0.12208 0.027631 -0.26625 -0.019734 0.23102 0.087615 -0.0076915 0.019005 -0.44212 -0.0682\n",
            "he 0.10278 -0.037982 -0.34679 -0.20236 -0.10104 -0.0041614 -0.18122 0.052666 0.63239 -0.017635 0.29064 0.55232 -0.18253 0.032052 0.10706 0.28863 -0.5465 0.63784 0.26307 -0.35245 0.78052 3.2884 0.13932 -0.1764 -0.21195 0.31297 -0.35545 -0.084663 0.19614 -0.36436 -0.4838 -0.029026 0.14678 -0.3716 0.035807 -0.60569 -1.0662 -0.24823 0.086176 0.44917 -0.27971 0.072874 -0.32838 0.45463 -0.087686 -0.22879 0.4479 0.56725 0.11629 0.18263 0.27651 0.48955 -0.047938 0.64848 0.087681 -0.39107 0.16413 -0.20127 -0.3754 0.021114 -0.13349 -0.37299 -0.27203 0.086235 0.32202 0.089046 -0.26556 0.33787 -0.014177 0.31975 0.3274 -0.47988 -0.058957 -0.01829 -0.13548 -0.27461 -0.38017 -0.31293 0.073876 0.0025744 0.42813 -0.17042 -0.20509 0.23494 0.16507 0.15267 -0.82546 -0.3771 0.30854 -0.60148 -0.16621 -0.13708 -0.031724 0.074703 -0.48448 -0.2303 0.24285 -0.1302 -0.06301 0.14626 -0.0081932 0.020477 -0.065081 0.38807 -0.070858 -0.2693 0.14757 1.0983 -0.18736 -0.10725 0.53126 -0.37668 0.24258 -0.17912 0.15185 -0.16 -0.086678 0.29508 -0.36161 -0.25959 0.15685 0.39739 0.024662 0.49537 0.16396 -0.36334 0.13761 -0.047526 0.48767 -0.60551 -0.37744 -0.27895 0.30921 -0.54864 0.23541 0.53319 0.0044727 -0.19318 -0.33792 0.032271 0.43456 -0.332 -0.16313 -0.12138 2.0354 0.64063 0.30325 -0.15715 -0.014365 0.069193 0.35589 -0.043891 -0.3299 0.14328 -0.20706 -0.58879 -0.087851 -0.1563 0.13603 -0.1601 -0.26251 0.30142 -0.029627 -0.070453 -0.24357 -0.15967 0.15829 0.19095 -0.50924 0.43491 0.057935 -0.20903 0.47752 -0.11511 0.32314 -0.061648 -0.65868 -0.1869 1.0805 0.063511 0.92858 -0.18946 -0.50856 0.18354 -0.4538 -0.47037 -0.42802 0.0049602 0.15261 0.011386 0.41096 -0.058602 -0.22928 0.10317 0.39274 0.42591 -0.25326 0.34194 0.23397 -0.045398\n",
            "as 0.36438 0.31464 -0.40387 -0.12262 0.047504 0.027443 -0.18495 0.42909 0.01831 -0.11065 0.32449 0.47943 0.056019 -0.015851 0.36826 0.11738 -0.3069 0.4719 0.17972 -0.48268 -0.003983 2.7734 -0.055091 -0.31441 0.12578 -0.10673 -0.010031 -0.069373 -0.026013 0.21809 0.070025 0.092294 -0.42643 0.024418 0.14871 -0.4125 -0.84502 -0.72545 -0.034937 0.088198 -0.041176 -0.10368 -0.20342 0.017247 -0.098891 -0.079597 0.35067 -0.0607 0.1432 0.35168 -0.34679 0.20076 -0.16554 0.58654 0.10436 0.026148 -0.1236 -0.2681 -0.33216 0.18431 -0.037109 -0.21601 -0.23836 0.15189 0.07617 0.091472 -0.034183 0.37332 0.19661 0.21825 0.61833 0.29393 0.10126 0.61124 -0.34064 0.23072 -0.24994 -0.3344 -0.12134 -0.28922 0.31747 -0.12831 -0.19276 0.076799 0.1223 0.31455 -0.48665 -0.12275 0.4597 -0.38303 -0.2929 0.092495 -0.19756 0.1648 -0.27075 -0.17946 -0.1979 -0.062728 0.046778 0.06524 0.32122 -0.072622 0.11672 0.38072 -0.12758 -0.22517 -0.23703 0.99657 -0.26167 0.13342 0.16977 -0.42944 0.034933 -0.061549 0.60732 -0.014297 -0.13385 0.25242 -0.43245 -0.2538 0.12047 0.1441 0.77602 0.45253 0.43784 -0.90705 -0.0054119 0.60024 0.29254 -0.40205 -0.13346 0.069888 0.32893 -0.39554 0.26085 -0.031653 -0.071965 -0.11096 0.031741 -0.18146 -0.090746 0.063655 0.37212 -0.1028 1.3115 0.038869 -0.2271 -0.59467 0.28157 0.076136 -0.14313 0.067323 -0.10865 -0.19487 0.38834 0.070976 -0.10856 0.26826 0.10279 -0.52305 0.24593 0.1208 0.036469 0.13261 -0.075075 -0.10488 0.058019 -0.079499 -0.25841 0.79497 0.0071308 0.1071 0.81741 -0.30615 0.0037483 0.18964 -0.32884 -0.3742 0.016414 0.0020921 1.156 -0.35766 -0.14719 0.055602 -0.13511 0.080765 -0.30223 0.17729 -0.23586 0.3123 0.0036631 -0.2089 -0.32392 0.1988 0.53798 -0.22862 -0.50103 -0.020566 0.074674 0.088034\n",
            "it 0.21632 0.21896 0.12569 -0.17436 0.17336 -0.043868 -0.37857 -0.14673 0.17779 -0.012025 0.19679 0.49533 -0.10004 0.016557 0.085587 0.19353 0.018015 0.45869 -0.073211 -0.5201 0.3916 3.1288 -0.20053 -0.22796 0.288 -0.35202 -0.24255 0.39615 -0.088477 -0.44213 -0.18451 -0.36414 -0.059358 0.0038449 -0.32244 -0.30023 -1.1532 -0.60431 -0.044546 -0.054329 -0.42018 -0.2609 -0.075203 0.39259 -0.1712 0.16186 0.58031 0.14301 -0.0091005 0.063381 0.13493 -0.41165 -0.083047 0.22028 0.28274 -0.10288 -0.58171 -0.10804 -0.29386 0.17034 0.085259 0.015873 0.035313 -0.073292 0.17886 0.16451 -0.17836 0.16759 -0.00019414 -0.03302 0.46834 -0.0061928 -0.06925 0.3838 -0.64673 0.3634 -0.17243 -0.11025 -0.6222 -0.0073716 0.12671 -0.19604 0.24839 0.19266 0.22559 -0.37689 -0.66871 -0.47979 0.39652 -0.9192 0.38489 0.15571 0.77107 -0.15432 -0.49297 -0.051087 -0.060623 -0.12003 -0.20142 -0.43947 0.072874 0.54488 0.15 0.29057 -0.033656 0.045901 -0.030017 1.2601 -0.51029 -0.099797 0.27948 -0.16585 0.047892 -0.092442 0.022111 -0.18219 0.056019 -0.25 -0.21671 -0.11378 0.26168 0.37362 0.30048 -0.28303 -0.028134 -0.37524 0.33185 0.02748 0.15299 -0.51839 -0.32336 0.19303 0.30017 -0.54381 0.30662 0.42139 0.14094 -0.12844 0.16161 0.03916 0.071101 -0.12043 0.23926 -0.45233 1.3905 0.35396 0.030238 -0.78879 0.19193 -0.052302 0.1836 0.52903 -0.40159 0.26208 0.64232 -0.43576 -0.51035 0.19077 0.13147 -0.25845 0.15282 -0.23367 -0.096225 -0.076273 -0.060554 -0.040525 0.11783 0.27745 -0.42597 0.26544 0.07219 0.54081 0.32599 -0.29222 0.1574 -0.0392 0.00078993 0.040421 0.28956 -0.098087 1.6954 -0.35001 -0.31789 0.32883 -0.11232 -0.019071 -0.023109 0.077824 0.20826 0.6104 -0.10016 -0.021571 -0.37894 -0.058381 0.19228 -0.0034271 -0.16743 0.78661 -0.15524 -0.36713\n",
            "by -0.57382 0.079024 -0.055426 -0.28968 0.24586 -0.044329 -0.25122 -0.2085 0.13136 -0.49581 0.69533 -0.21534 0.12439 0.2277 0.31425 0.047488 0.0183 0.47598 -0.21365 -0.19251 0.55798 2.9505 0.30497 -0.097325 0.22793 0.23193 -0.26728 -0.077724 0.23149 0.19438 -0.21407 0.46663 0.51505 -0.037818 -0.47883 0.1602 -0.24775 -0.64107 0.50578 -0.5564 0.58326 -0.50548 -0.065012 0.054993 -0.051197 -0.27751 0.23215 0.17907 0.038308 -0.084303 -0.4602 0.074397 -0.35713 -0.038031 -0.24509 0.14478 -0.73178 0.55225 0.21815 -0.14783 -0.094385 0.51471 -0.10121 -0.31703 0.027571 -0.37418 -0.42587 0.5351 -0.12781 0.084672 -0.052263 0.29491 -0.024964 0.65858 -0.36101 0.66203 0.08749 -0.60706 -0.33804 -0.45988 -0.28788 -0.063587 -0.55874 0.099788 0.21739 0.63578 0.095174 -0.30842 0.29006 -0.33596 -0.10431 -0.028255 0.32514 0.37824 -0.83834 0.98873 -0.15196 -0.45058 0.10989 -0.14665 -0.23621 -0.35256 -0.029076 0.066204 -0.79896 -0.071402 -0.33421 0.99566 -0.23211 -0.19901 -0.19668 0.073347 -0.29723 -0.038668 0.50934 0.27097 0.11101 0.20846 -0.50029 -0.31254 -0.29405 0.06647 0.33848 0.13432 0.64571 -0.73114 0.25996 0.33017 0.30444 -0.097642 -0.3338 0.083818 0.38259 -0.38957 0.84697 0.78648 -0.044068 0.5211 -0.16962 -0.1037 -0.60742 -0.14739 -0.32457 -0.43331 1.0209 0.7425 -0.5266 -0.59274 -0.24064 -0.11076 -0.82215 0.63424 -0.64505 -0.29631 0.11511 0.1549 -0.55878 0.19219 -0.054706 -0.64911 0.35893 0.76641 0.048747 0.46142 -0.1408 0.44957 0.62594 0.21464 -0.32243 0.2931 -0.0058492 0.12113 0.38909 0.075938 -0.1439 0.22804 -0.45898 0.054083 -0.31156 0.10394 1.4941 0.19628 0.44821 0.33783 -0.016429 -0.82871 -0.43747 -0.43573 0.083263 0.16475 -0.58455 0.21914 -0.36186 0.12896 0.25956 0.39557 0.10577 0.302 -0.018419 0.14293\n",
            "at 0.39925 0.48812 -0.63552 -0.83671 -0.24701 0.45435 0.26975 -0.74806 0.32203 0.36562 0.58945 0.038984 0.18854 -0.23607 0.45707 0.45385 -0.15287 -0.088254 0.11244 -0.02164 0.094423 2.9844 0.23742 -0.23244 0.19917 0.50029 -0.23519 0.53942 -0.32362 0.1368 0.22834 0.017505 -0.11235 -0.050325 -0.61333 -0.21298 -0.9115 -0.2783 -0.22977 0.78089 0.2193 -0.17475 0.59294 0.58902 -0.46914 0.53419 0.50555 0.037082 0.27287 0.19961 -0.24238 0.20792 -0.063335 1.1269 0.29088 -0.14476 0.21312 0.59473 0.17349 0.024098 0.32602 0.4298 0.063134 0.5362 0.11468 -0.03288 -0.37136 0.19754 0.32593 0.63269 -0.10092 -1.0753 0.42362 0.57697 0.046648 0.38366 -0.036844 -0.013513 0.2324 -0.28042 -0.16817 -0.37811 0.33678 0.55439 0.089686 0.23842 -0.11818 -0.44342 0.75466 -0.11622 0.027508 -0.19803 0.0085431 -0.014912 0.11231 0.20279 0.55486 -0.8102 0.062486 -0.15463 -0.41898 0.38182 -0.16746 0.93769 -0.5144 -0.36573 0.44684 1.6005 -0.34012 0.54359 0.32114 0.094758 0.44744 0.55912 -0.16644 -0.47393 0.15328 -0.10836 0.48581 -0.06065 0.35854 -0.453 0.11835 -0.014004 0.5298 -0.40621 -0.051263 0.057362 -0.33419 -0.36255 0.00016107 -0.19761 0.68551 -0.56668 0.061099 0.17806 0.36831 -0.21512 -0.31876 0.49447 -0.43257 -0.045146 -0.53978 -0.054618 1.0955 0.33786 -0.2506 -0.026255 -0.090536 0.63178 0.66403 0.32904 0.068354 -0.22975 -0.024711 0.19082 -0.32597 -0.092845 -0.29052 -0.97882 0.0022326 -0.90963 0.41257 0.2824 -0.10098 -0.1103 -0.034622 0.67631 -0.85891 0.7622 -0.23844 -0.28335 0.1328 -0.62978 -0.41655 0.019215 -0.0060994 -0.65445 0.31639 -0.31538 0.66422 0.40203 -0.47839 0.17426 0.11115 -0.52603 -0.78383 0.13274 -0.38645 -0.046796 0.17552 0.53912 0.28622 0.16891 0.33966 0.48645 -0.79241 -0.11872 0.51562 -0.04393\n",
            "( 0.10614 0.37697 -0.098654 -0.037704 0.22438 -0.26938 -0.18527 -0.39687 -0.061702 -0.12708 -0.44384 0.69292 0.43437 -0.44096 0.68139 0.41268 -0.4984 0.45288 0.21723 -0.56937 -0.016087 2.5319 -0.52512 0.1095 -0.21671 -0.03089 -0.18728 0.50558 -0.20177 0.51162 0.42304 0.39904 -0.77813 -1.0809 -0.0080969 0.06044 -0.10485 -0.65235 0.38518 -0.46104 -0.15291 -0.43351 -0.090194 -0.69887 -0.12142 0.39802 0.64449 -0.24036 0.39336 -0.15419 -0.49543 -0.59362 0.49696 1.3399 -0.091407 -0.11069 0.014491 0.78729 0.48993 -0.35808 0.41077 -0.13998 -0.32903 -0.46218 -0.60294 -1.0092 0.20433 -0.13033 0.32272 -0.17901 0.51601 0.48102 -0.75807 0.61869 0.10427 -0.32326 0.17909 -0.014495 0.11612 -0.30118 -0.18137 -0.44858 0.015607 0.2235 0.14175 -0.52019 -0.1824 0.66427 0.67132 0.54628 -0.57413 -0.29717 -0.27383 0.37917 0.2514 0.8725 -0.23802 -0.59102 0.21998 -0.039978 0.23257 0.75914 0.60029 0.3722 0.057051 -0.55805 0.041646 1.0836 0.46166 0.33262 -0.29171 0.4392 -0.39419 0.32338 -0.11596 0.0053049 -0.0085828 0.92176 0.079524 -0.14312 -0.33046 -0.48247 0.84904 0.11993 0.80585 -0.58681 -0.16383 0.47231 0.14329 0.0022554 -0.33304 -0.22728 -0.39976 0.38334 -0.032465 -0.15987 -0.046775 -0.18658 -0.21447 -0.13076 0.41658 -0.083236 -0.091862 0.24889 0.6814 -0.098528 0.19782 0.14179 -0.017627 0.20805 0.051812 0.62061 0.25496 -0.44798 0.69051 0.047921 -0.25826 -0.90535 0.016771 -0.54989 0.39088 0.45524 -0.82821 -0.21731 -0.18544 0.72408 -0.12519 0.41823 0.022256 0.56986 -0.32683 0.12082 0.8624 -0.34624 -0.17439 0.46269 0.1851 -0.0081435 0.37812 -0.41676 1.0189 -0.70945 -0.1939 0.51858 -0.31703 -1.3074 -0.28126 -0.25087 0.27718 0.26981 -0.75549 0.51003 0.37104 -0.12224 -0.22088 0.16724 0.12704 0.077388 -0.81578 0.3324\n",
            ") 0.18252 0.39579 -0.047836 -0.051301 0.2075 -0.28372 -0.11125 -0.26668 -0.063935 -0.15941 -0.37085 0.63728 0.31514 -0.526 0.61228 0.4666 -0.45012 0.51583 0.204 -0.64649 0.011652 2.613 -0.53519 -0.023799 -0.15736 0.015843 -0.21555 0.65628 -0.12659 0.30604 0.44325 0.21618 -0.78338 -0.98079 -0.0085923 -0.02119 -0.31045 -0.61546 0.45434 -0.48489 -0.25129 -0.38904 -0.08332 -0.61008 -0.1626 0.37297 0.5792 -0.28597 0.40933 -0.21266 -0.45256 -0.56049 0.51311 1.332 -0.16509 -0.15751 0.11052 0.77287 0.40923 -0.31906 0.25337 -0.26502 -0.27258 -0.43233 -0.6134 -0.99027 0.2781 -0.037326 0.38288 -0.28159 0.45947 0.47837 -0.68361 0.74066 0.016955 -0.31524 0.27007 -0.042647 0.18332 -0.41793 -0.15581 -0.52765 0.21633 0.23007 0.17967 -0.57986 -0.19347 0.65842 0.74057 0.5311 -0.57563 -0.19006 -0.21672 0.38691 0.20864 0.74164 -0.30259 -0.52261 0.3102 0.067365 0.21224 0.89949 0.53728 0.45326 0.043801 -0.57274 -0.013416 1.0892 0.55125 0.2302 -0.20608 0.27367 -0.29941 0.4397 -0.0099586 -0.11267 0.14624 0.97168 0.00463 -0.23397 -0.34411 -0.48189 0.86434 0.21248 0.69263 -0.60455 -0.12048 0.36558 0.20717 -0.16688 -0.38464 -0.12655 -0.23131 0.3736 -0.1355 -0.15214 -0.074811 -0.28681 -0.17627 -0.17093 0.52842 -0.12755 -0.0252 0.1569 0.93169 -0.067882 0.26184 0.13441 -0.063493 0.038748 0.090139 0.492 0.1799 -0.41806 0.77437 -0.00047847 -0.33275 -0.87847 0.063479 -0.57412 0.40241 0.53486 -0.79542 -0.15849 -0.25584 0.72366 -0.074082 0.48936 -0.053332 0.65991 -0.30601 0.18193 0.84938 -0.48411 -0.11651 0.45298 0.16122 0.019913 0.42234 -0.45698 1.1631 -0.76981 -0.20062 0.43403 -0.20262 -1.2827 -0.25828 -0.33408 0.25105 0.29832 -0.76301 0.40263 0.32793 -0.18681 -0.14676 0.21045 -0.019274 0.10211 -0.78425 0.29008\n",
            "from -0.16928 -0.035512 0.015382 -0.25714 0.23063 0.06305 -0.043813 0.025437 -0.48344 0.15332 0.26501 0.44495 0.28427 -0.32765 0.63706 0.029678 0.43316 0.29092 0.0083971 0.068337 0.56633 3.2228 0.064591 -0.10414 9.9533e-06 0.29699 -0.63743 -0.17349 0.20598 -0.073979 0.13355 -0.20671 0.0039752 -0.062961 -0.18895 -0.11436 -0.60493 -0.40829 -0.20248 0.23106 0.2688 -0.24025 0.039355 0.52718 -0.00065019 -0.29321 0.45561 0.50145 0.40752 0.49195 -0.30595 -0.072132 0.28914 0.3582 0.2952 0.31045 -0.38406 0.029748 -0.3964 0.096401 -0.28502 -0.43945 -0.29363 -0.25249 0.4584 -0.21557 0.00077282 -0.17065 -0.11941 -0.44947 -0.038962 0.15462 -0.11447 0.18756 0.40446 0.51278 0.23374 -0.090159 -0.41571 -0.23921 -0.09168 -0.3722 -0.44009 0.63998 8.1489e-05 -0.11108 0.42527 -0.40384 0.72372 -0.060024 -0.50792 -0.1348 0.16273 0.17833 -0.54739 0.39909 -0.48311 -0.24892 -0.20674 -0.2161 -0.24712 0.28043 -0.081212 0.31803 0.20318 -0.3037 0.35637 1.2656 -0.80495 -0.35303 0.065518 0.07688 0.59695 0.68027 0.12767 -0.065946 0.082866 0.3122 0.1568 -0.83571 -0.37289 -0.009254 -0.18326 0.11604 0.27535 -0.53493 -0.098806 0.6188 -0.07123 -0.17602 -0.34745 0.023234 0.27571 -0.38192 0.13018 0.21995 -0.14856 0.046063 -0.37755 -0.08714 0.15114 -0.04505 -0.023464 -0.014839 1.443 0.13143 -0.13879 -0.18039 0.13761 -0.076921 0.17749 0.71448 -0.24248 -0.069206 -0.10581 -0.078489 -0.11824 -0.089953 -0.33376 -0.5237 -0.26431 -0.10257 -0.15447 -0.34765 0.037624 0.76904 -0.18628 -0.18178 -0.047568 0.46792 -0.3037 0.10668 0.080202 0.55416 -0.065492 0.06898 0.081131 -0.048846 0.31611 -0.46599 0.93176 -0.25823 -0.51351 -0.012557 0.1499 -0.38756 -0.082904 -0.089126 -0.25097 0.28398 0.1735 0.69329 -0.14405 0.28026 -0.06218 0.071932 -0.48149 -0.088303 0.22052 0.74344\n",
            "his -0.27002 -0.16067 0.066515 -0.52124 -0.094791 0.12395 -0.015233 -0.010942 0.0093558 0.11741 -0.19151 0.37225 -0.11444 0.37209 0.57027 0.072209 -0.38037 0.56744 -0.27584 -0.29915 0.53716 3.234 0.61755 -0.041772 0.016927 0.47861 -0.42695 -0.26614 -0.22283 -0.30836 -0.83129 0.031708 0.48611 -0.39461 -0.20405 -0.14476 -0.66294 -0.085002 -0.014626 0.10978 -0.37059 -0.15414 -0.093201 0.57348 -0.0288 0.045927 0.091574 0.75236 0.042547 0.011114 0.10725 0.31544 0.11039 0.37984 0.39131 -0.23319 0.38108 -0.025377 0.12458 0.029508 0.051679 -0.41149 -0.99742 -0.40902 0.0076677 -0.1147 -0.081738 0.15131 0.11018 0.16003 0.24294 -0.41872 0.048349 0.138 0.099553 -0.10435 -1.1409 -0.6056 -0.0122 0.14398 0.53029 0.083272 -0.44132 -0.31226 0.5536 0.29765 -0.49141 -0.74094 0.46249 -0.65685 -0.080812 0.35996 -0.2792 0.62088 -0.46297 -0.40052 -0.030983 -0.29279 0.34101 0.4236 -0.46606 -0.16867 -0.26364 0.12329 -0.62468 -0.63525 0.47773 0.92416 -0.22558 -0.60245 0.23708 -0.45433 -0.45251 -0.26017 -0.046001 0.46437 -0.16589 0.48278 0.00052534 -0.7243 0.32558 0.54023 -0.26951 0.37526 0.76966 -0.19603 0.31849 -0.10482 0.46023 -0.0091697 -0.35073 0.0035128 0.38199 -0.61741 -0.064229 0.85169 0.098449 -0.14159 -0.48155 -0.26448 0.25615 0.20852 0.096748 0.46412 2.1627 0.36636 0.26652 -0.12869 -0.24046 0.37517 0.36001 -0.13096 -0.12757 0.10667 -0.308 -0.23261 -0.31226 -0.11248 0.0096936 -0.17477 0.40333 0.16438 -0.24643 -0.072397 0.36526 0.11542 0.20688 -0.13413 -0.09221 0.92742 0.16167 -0.25909 0.46959 0.17633 0.099677 0.45298 -0.73499 -0.64646 1.0433 0.30424 0.34574 0.15241 -0.16375 0.021106 -0.39377 -0.40647 -0.29685 -0.3077 -0.036177 0.1096 0.47117 0.031807 -0.18969 0.1817 0.44191 -0.18987 0.20682 0.49099 0.079434 0.52251\n",
            "'' 0.16559 0.63899 0.19219 -0.29969 -0.24632 0.61178 -0.86763 -0.067066 -0.36131 0.33786 0.57972 0.63048 0.35361 -0.10705 0.6692 0.007708 -0.61091 0.56761 -0.071283 0.12543 0.86978 2.6159 0.33817 0.38699 -0.23786 0.042156 -0.019513 -0.62849 0.078484 0.050754 -0.66159 0.34727 0.044022 -0.33348 -0.12338 0.087718 -0.56557 -0.22654 -0.055674 0.88787 0.12034 -0.0073492 -0.68894 0.2586 -0.31574 -0.26604 0.93324 -0.080103 0.070681 -0.1403 0.18402 0.41121 -0.20591 -0.26849 -0.18991 -0.63995 0.1153 -0.16977 0.0043878 0.069422 0.73197 -0.20179 -0.32447 0.13115 -0.19253 -0.10831 0.0762 0.75447 0.056915 0.64733 0.46394 -0.31101 0.43282 0.68876 -0.76373 0.28267 -0.1025 -0.04071 -0.89403 -0.080291 -0.1724 -0.68524 -0.010493 0.56328 -0.32508 -0.31328 -0.61087 -0.115 0.14656 -1.612 -0.048406 -0.21671 0.36942 -0.17586 -0.69423 0.52185 -0.019879 0.16688 -0.23911 -0.197 0.26333 -0.14477 0.3606 0.34923 0.20075 -0.09853 -0.46189 1.6714 -0.48265 0.22728 0.066882 0.0034454 -0.30973 -0.12316 -0.11509 -0.023004 0.30777 -0.32061 -0.11528 0.2603 0.59596 0.52482 0.71461 -0.68739 -0.59138 -0.41573 0.0035476 -0.36249 0.40602 -0.26656 0.19471 -0.3637 -0.21059 0.24575 0.8312 -0.41779 0.65966 -0.49108 -0.43993 -0.2639 0.44025 0.24576 -0.031963 -0.32575 1.2665 0.44465 0.14853 -0.26154 0.0026851 0.45969 0.28536 1.0354 -0.47881 0.59362 0.54921 -0.15371 -0.0012089 0.20182 0.47226 -0.042077 0.11282 -0.013804 -0.059743 -0.55705 0.42153 -0.75828 0.43591 0.14769 0.070701 -0.13356 0.18539 0.054574 0.30843 0.1834 -0.32382 -0.42491 -0.41206 -0.24179 -0.26889 1.126 1.0328 -1.0725 -0.77839 0.59385 -0.72198 -0.68467 -0.2123 -0.050394 -0.32139 0.30344 -0.38234 0.19638 0.38902 -0.061509 0.33789 -0.75884 0.092476 0.32175 0.2194 0.2941\n",
            "`` 0.2413 0.67803 0.050612 -0.31306 -0.28523 0.11966 -1.0117 0.073539 -0.49591 0.39344 0.39115 0.45168 0.24553 -0.19113 0.47662 -0.11378 -0.6715 0.80226 -0.11375 0.25467 0.96132 2.8108 0.18122 0.46974 -0.05287 0.13719 -0.0072787 -0.61194 -0.012008 0.04181 -0.73516 0.1998 0.013249 -0.18786 -0.40396 -0.022443 -0.65815 -0.41481 -0.046237 0.79758 0.3102 0.017754 -0.66972 0.30328 -0.17774 -0.02761 0.76822 -0.114 -0.080623 0.038337 0.20763 0.36914 -0.039319 -0.30807 0.038063 -0.65279 0.10934 -0.34798 -0.31272 0.26092 0.72356 -0.38237 -0.5111 -0.013123 -0.42106 -0.0051115 0.057043 0.82003 0.27889 0.53981 0.41318 -0.11121 0.39203 0.62629 -0.88745 0.30122 -0.15964 -0.04359 -0.8217 -0.29032 -0.16796 -0.72632 0.11013 0.44996 -0.52411 -0.28171 -0.5968 -0.066989 0.20176 -1.6116 0.068363 -0.0862 0.55332 -0.11617 -0.68851 0.30632 -0.0019373 0.0559 -0.073226 -0.11551 0.20995 0.026739 0.64385 0.36475 0.27807 -0.11095 -0.42645 1.4995 -0.46993 0.2504 -0.022105 -0.16142 -0.36741 0.13231 -0.14018 0.096804 0.098086 -0.2659 -0.31992 0.038094 0.46511 0.17681 0.74658 -0.59708 -0.55305 -0.48013 0.10228 -0.37906 0.27329 -0.39408 0.0087392 -0.12275 -0.16812 0.017379 0.51016 -0.51239 0.40234 -0.36928 -0.41084 -0.22743 0.11114 0.2357 0.10891 -0.43797 1.5043 0.46759 0.27184 -0.51287 -0.089362 0.48223 0.27573 1.0245 -0.57927 0.34388 0.69249 -0.068839 -0.04539 0.21999 0.47082 0.12742 0.24376 -0.13082 0.027108 -0.41553 0.50063 -0.67746 0.4768 0.13512 0.00077947 -0.2388 0.14962 0.070624 0.33472 0.15152 -0.28528 -0.40881 -0.4157 -0.14091 -0.047405 1.1428 1.2294 -0.84494 -0.69146 0.55598 -0.58338 -0.61986 -0.30994 -0.13265 -0.23404 0.28846 -0.56373 0.14145 0.37001 0.045382 0.43666 -0.76026 0.016645 0.42503 0.44938 0.56934\n",
            "an 0.77438 -0.049763 -0.27208 -0.59821 0.35714 0.11376 -0.004672 0.007186 -0.14772 0.073092 0.12199 0.48286 0.27292 -0.15812 0.8881 -0.33209 0.25711 -0.17972 0.38133 -0.29656 0.76714 3.184 -0.070868 -0.18067 0.056668 0.092714 -0.10972 -0.038707 0.22224 0.14124 -0.38076 0.36401 0.70957 -0.25826 0.36981 -0.3288 -1.0803 -0.75447 -0.44897 0.20272 0.36221 -0.017887 0.45972 0.033516 0.066242 -0.1033 0.064978 0.20277 0.2766 0.55564 0.2043 -0.22754 -0.092248 -0.1338 -0.12269 -0.16021 0.11778 0.25749 0.035557 -0.087638 -0.067571 -0.72185 -0.52484 0.011323 -0.07644 -0.31383 0.36575 0.30164 0.16449 -0.015076 0.33331 -0.39207 0.23467 0.58109 -0.45401 0.59222 0.013985 -0.087078 -0.64382 -0.10844 0.52803 -0.61961 0.84338 0.44079 0.081609 0.40562 -0.32657 -0.3701 0.56687 0.20551 0.051275 0.074996 0.25629 0.20002 -0.72811 0.39739 0.28019 -0.18867 0.22336 0.71375 -0.35524 0.14696 0.14802 0.269 0.24956 -0.71826 0.18282 1.5781 -0.35237 -0.050352 0.022392 -0.39102 -0.056161 -0.15518 0.35844 0.028668 0.38662 -0.011646 -0.67286 -0.2496 0.12089 0.36506 0.19042 0.45523 0.23494 -0.064237 0.25059 -0.10456 -0.097676 -0.37521 -0.058192 -0.0077616 0.79728 -0.29236 0.028219 0.84881 0.41286 -0.36422 -0.57135 -0.016493 0.14303 0.75231 -0.020154 -0.18598 1.6126 -0.28759 -0.01555 -0.36629 0.35105 0.23792 -0.7061 0.30915 -0.15417 -0.001262 0.26623 -0.49523 0.15108 0.10165 0.31778 -0.70273 -0.25456 -0.35988 -0.30951 -0.0111 0.13582 -0.017615 -0.15873 0.19496 -0.77542 0.28602 0.2173 0.13774 0.58612 -0.10415 -0.087568 -0.24211 -0.1015 -0.21595 -0.23387 -0.0045025 1.5367 -0.72311 0.11745 -0.16221 0.074326 0.34121 -0.80884 0.010289 -0.1798 0.35401 -0.1092 -0.23419 0.37289 -0.16091 0.1024 -0.15596 -0.35526 0.4652 -0.33322 -0.23325\n",
            "be 0.14336 0.32323 -0.0012141 -0.30418 0.032943 0.1126 -0.24415 -0.094201 0.55483 -0.33432 0.3424 -0.17095 0.13932 0.051725 0.45465 0.26129 0.22363 1.0396 0.38437 -0.66331 -0.10256 3.5409 -0.41395 0.01552 0.24559 -0.28381 -0.1787 -0.027111 0.0046549 0.10711 -0.1357 0.18047 -0.089003 0.21724 -0.086447 -0.11313 -0.80052 -0.9377 0.33554 0.46958 0.013144 -0.20135 -0.0061933 0.15843 -0.26722 0.0082961 0.57876 -0.22335 0.17597 -0.48894 -0.20757 -0.12981 -0.6218 0.45908 0.45471 -0.23861 -0.18473 -0.3393 -0.46309 0.02537 0.26742 0.67275 0.087877 -0.098783 0.12241 -0.12099 -0.17459 0.39869 -0.35029 0.58581 0.63044 0.19351 -0.021769 0.47182 -0.6906 0.0013069 -0.80857 -0.62236 -0.10511 -0.43516 -0.084013 -0.26261 -0.051571 -0.044176 0.2687 -0.043707 0.12403 -0.38273 0.18689 -0.7861 0.065988 -0.22175 0.69074 0.1705 -0.24844 0.55655 -0.12323 -0.13789 -0.19014 -0.39274 0.47582 -0.31446 -0.01531 0.24052 -0.0095921 -0.23365 -0.59129 0.97654 -0.53055 -0.094225 -0.18381 -0.18811 0.17707 -0.090836 0.28539 -0.042806 -0.15771 -0.064607 -0.49908 -0.40296 0.31553 -0.25753 0.65408 -0.38378 -0.55686 -0.45548 0.13884 0.10403 -0.15466 -0.28213 -0.21216 0.13189 0.33354 -0.29124 0.6129 0.16283 -0.29116 0.078644 0.052997 0.046805 -0.44462 -0.16522 0.26855 -0.55974 1.4265 0.51933 -0.46959 0.042457 0.060384 0.027037 -0.23212 0.50623 -0.42049 0.13505 -0.13639 -0.15631 -0.45753 0.37171 0.25586 -0.061305 -0.32502 0.18703 0.62817 -0.19403 -0.08864 0.088848 0.10697 0.046341 -0.44787 0.44155 -0.081044 0.22345 0.63931 -0.25571 0.36059 0.20647 -0.34467 -0.25786 -0.15711 0.13742 1.699 -0.15331 -0.21097 -0.21055 -0.0081241 -0.038224 -0.27727 0.10088 -0.34081 0.40819 -0.34789 -0.20936 -0.064287 -0.071423 0.19958 -0.074355 0.00038379 -0.060958 0.0050852 0.26671\n",
            "has -0.30666 -0.08218 -0.32038 -0.11622 0.093608 0.17793 -0.33245 0.21492 -0.072436 -0.46874 0.18477 0.61453 -0.20251 -0.13487 0.44676 0.36254 -0.42225 0.5666 -0.29827 -0.34243 0.42679 3.3001 -0.28998 -0.33333 0.09131 0.065061 0.37465 -0.35017 -0.15619 -0.26084 -0.46292 -0.31747 -0.06389 -0.2991 -0.07401 -0.27748 -0.91909 -0.35451 -0.17093 -0.040298 -0.22645 -0.42929 -0.45291 0.20596 -0.033507 -0.42609 0.39832 -0.058789 0.2602 -0.15884 0.24484 -0.2402 -0.39166 0.39319 0.53458 -0.31889 -0.41591 -0.18064 -0.32338 0.24257 0.16489 0.30916 -0.5008 -0.18773 0.35669 -0.30113 -0.64408 -0.097853 -0.071267 0.029457 -0.21639 0.14606 -0.14995 0.34746 -0.38243 0.26069 -0.11574 -0.49879 -0.22083 -0.13354 0.15081 -0.50152 -0.65698 -0.090877 0.21886 -0.2531 -0.37492 0.22614 0.41869 -0.51884 0.23991 0.024469 0.53314 -0.44814 -0.68508 0.17484 0.17319 0.14164 -0.050175 -0.29463 0.10051 -0.037877 -0.28321 0.5168 -0.26878 -0.25986 -0.41355 1.1511 -0.28658 -0.70869 0.36624 -0.57766 -0.37566 -0.12638 0.39857 0.06567 -0.16428 0.6968 -0.45244 -0.0046899 -0.23686 0.47644 0.022571 0.10974 0.071907 -0.44087 0.19986 -0.27222 0.11025 0.06374 -0.12939 -0.41598 0.18226 -0.0056904 0.22351 0.40858 -0.1822 0.17534 -0.11694 0.057238 0.15903 0.13096 0.059284 -0.19061 1.237 0.34662 0.24908 -0.53956 0.16379 -0.15569 -0.39953 -0.29861 -0.18873 0.24043 0.33602 -0.46598 -0.75666 -0.022526 0.098502 -0.54569 -0.084472 -0.0099459 0.30445 0.2147 -0.1512 0.29834 0.066287 0.20022 -0.050626 0.77979 0.075801 0.091628 0.28571 0.10389 -0.010093 -0.12553 -0.423 -0.39648 0.063905 0.011085 1.1736 0.30007 -0.18178 0.1073 -0.17771 -0.042847 -0.31662 0.18466 -0.089576 0.20389 -0.084274 0.11638 -0.39016 0.29415 -0.022398 -0.080495 0.030962 0.26902 0.23801 -0.16577\n",
            "are 0.036749 0.19894 -0.093035 0.071954 0.15242 0.29923 -0.61104 0.4613 -0.40526 0.024928 0.047561 0.17306 -0.25249 -0.20388 0.09701 0.30914 0.25983 0.76764 -0.11836 -0.36704 -0.08191 3.1783 -0.20902 -0.48355 0.31109 -0.21255 0.15967 -0.2045 0.17348 -0.0023584 0.31374 0.10931 -0.33768 0.72201 -0.01754 -0.52595 -0.82086 -0.72315 0.59128 0.46894 0.43322 -0.38602 0.25726 0.12669 0.0030499 -0.061387 0.96647 -0.84009 0.12175 -0.21294 -0.48029 -0.22124 -0.49764 0.38422 0.40001 -0.27206 -0.043716 -0.36294 0.041367 0.18605 0.56964 0.94211 0.0379 0.41438 -0.098364 -0.056479 -0.010501 0.56328 -0.074309 0.075357 0.55544 0.21169 -0.58412 0.51504 -0.34872 0.10985 -0.56704 -0.20564 -0.21688 -0.33047 -0.28397 0.52192 -0.4795 0.18359 0.43076 0.07595 0.30951 -0.24629 0.44948 -1.0294 -0.058655 -0.2789 0.58608 -0.25831 0.20782 0.36639 0.51021 -0.26213 -0.15569 -0.41474 0.82445 -0.026007 -0.16576 0.11062 0.074737 0.37823 -0.078609 1.1907 -0.11018 0.15263 -0.47316 -0.23535 0.46796 0.40863 0.34789 0.08721 -0.057653 0.22394 -0.43075 -0.72216 0.50118 0.44878 0.18714 -0.27663 -0.59756 -0.84121 0.21271 0.35853 0.28475 0.037163 -0.461 0.37082 0.31134 -0.24655 0.15201 -0.13641 -0.34281 -0.13407 -0.022612 -0.10063 -0.38793 0.078431 0.04933 0.034937 0.97701 0.66735 -0.014395 0.059589 -0.098003 -0.10301 -0.17885 0.61452 -0.53368 -0.628 0.63966 -0.089118 -0.18325 0.27608 0.048505 -0.054834 0.060384 0.14677 0.15108 0.24453 -0.12397 0.3914 0.28152 0.26042 -0.35671 0.4788 -0.65595 0.2194 0.16386 0.45261 0.0083746 0.38203 -0.36003 -0.4844 -0.40209 0.065195 1.3138 -0.27368 -0.39179 -0.046157 0.33308 0.026205 0.21055 0.22581 -0.64364 0.056954 -0.38106 0.06219 0.11297 0.3132 0.19591 -0.21073 -0.1542 -0.013302 -0.0039236 0.71276\n",
            "have -0.243 -0.014334 -0.38246 -0.21259 -0.095778 0.12093 -0.7266 0.28395 -0.29065 0.33459 -0.031752 0.37894 -0.037387 -0.21609 -0.13678 0.3971 -0.39391 0.97228 -0.37887 -0.27013 0.082613 3.4546 -0.48985 -0.39894 0.046237 -0.10497 0.13418 -0.42005 0.03453 -0.17336 -0.026703 -0.15447 -0.040138 -0.069576 0.089384 -0.35858 -0.74873 -0.46214 0.14009 0.27095 0.27864 -0.2972 -0.11797 0.26947 -0.15614 -0.15243 0.81632 -0.4313 0.15366 -0.083965 -0.23563 -0.10268 -0.64896 0.59497 0.6689 -0.53026 0.0035998 0.040686 -0.16159 0.24223 0.40909 0.65137 -0.44669 0.054007 0.36416 -0.11971 -0.61448 0.16627 0.039802 -0.14131 -0.095913 0.12335 0.077366 0.097338 -0.13635 0.028163 -0.1706 -0.067638 -0.041193 -0.32084 0.048141 0.065904 -0.70648 0.21365 0.28312 -0.015492 -0.15126 -0.2008 0.059213 -0.90237 0.34807 -0.088431 0.84551 -0.26246 -0.4066 0.39838 0.30456 0.078926 -0.16898 -0.53113 0.49855 -0.40339 -0.29788 0.07533 0.079453 0.42679 -0.27296 0.99014 -0.24139 -0.74268 -0.014792 -0.29786 -0.079509 0.20685 0.57429 0.37167 -0.27954 0.35843 -0.28551 -0.23087 0.42169 0.36308 0.29409 -0.0058696 -0.14322 -0.83146 0.070881 0.15132 0.54852 -0.15673 -0.36578 0.22601 0.28801 -0.049035 0.38071 0.28981 -0.47993 0.011544 -0.24011 -0.30405 -0.39671 0.12563 0.12836 -0.37588 1.3242 0.62149 0.078748 -0.49331 0.17932 -0.070516 -0.29337 -0.038606 -0.46321 -0.19355 0.003359 -0.29975 -0.46996 0.0377 0.08578 0.087872 -0.25806 0.35586 0.3689 0.028554 -0.40446 0.72911 0.2694 0.028046 -0.42522 0.50251 -0.020476 -0.03157 0.25363 0.35835 0.20739 0.033514 -0.55746 -0.47723 -0.14624 0.065349 1.3085 0.16449 -0.52071 -0.015065 -0.12383 0.054913 -0.12813 0.47714 -0.22757 0.4102 -0.29805 0.24732 -0.16811 0.21954 0.096379 -0.24085 0.14279 0.36901 -0.077209 0.48519\n",
            "but 0.24438 0.053703 -0.23639 -0.25545 0.18797 0.25274 -0.67528 0.060111 0.30357 0.34275 0.2434 0.56241 -0.13362 -0.21338 0.27329 0.29452 -0.2137 0.36726 -0.10583 -0.46335 0.33594 3.0291 -0.2609 -0.27682 0.078927 0.18592 -0.091115 -0.14342 0.042215 -0.38916 -0.33968 -0.1345 0.031568 0.057969 0.12065 -0.43677 -0.87031 -0.34831 -0.23486 0.1033 -0.19922 -0.27263 -0.19415 0.39412 -0.22311 -0.0067512 0.50752 0.13452 0.084267 -0.1644 -0.2242 -0.12909 -0.312 0.65054 0.16152 -0.23294 -0.0058667 -0.156 -0.044858 0.13797 0.11208 -0.074494 -0.3072 -0.0074617 0.55731 0.05247 -0.19197 0.16235 0.26831 0.20414 0.50148 -0.089077 0.016269 0.45699 -0.098283 0.098614 -0.44378 -0.19427 -0.23881 -0.074421 0.10298 -0.17764 0.15826 0.038483 0.37312 0.047815 -0.44967 -0.52037 0.0080561 -1.1086 0.056665 0.069532 0.43096 -0.1423 -0.34608 0.049953 -0.024184 0.035865 0.059182 -0.068924 0.46794 0.04814 0.072532 0.11331 0.028741 -0.049601 -0.11641 1.2508 -0.32569 -0.40437 0.076321 -0.34312 0.11947 -0.073512 0.18873 0.018313 -0.050186 -0.070998 -0.11023 0.036742 0.20843 0.38585 0.31216 -0.08266 0.092515 -0.43639 -0.0030814 -0.049689 0.37207 -0.1863 -0.14976 0.040397 0.42995 -0.55495 0.4294 0.16384 0.07971 -0.11106 -0.16367 -0.31854 -0.07988 0.097415 0.080348 -0.21838 1.5003 0.44506 -0.099058 -0.5727 0.21948 -0.09214 0.048814 0.27975 -0.072429 0.1474 0.15897 -0.54398 -0.33731 0.15299 -0.061892 -0.029032 -0.2191 -0.017324 0.20253 0.13862 -0.28553 0.20584 0.0068444 0.33154 -0.43667 0.29627 -0.098607 0.12109 0.067759 0.043778 0.089348 0.14997 -0.33814 -0.24332 0.2306 0.13254 1.3536 -0.12109 -0.55441 0.32485 -0.013406 0.10687 -0.097027 0.051368 0.056804 0.3033 -0.15848 0.22578 -0.18358 0.051548 0.31375 -0.28511 -0.20911 0.24556 -0.24603 -0.21292\n",
            "were -0.29716 -0.025477 -0.43389 -0.52616 -0.14354 0.33104 -0.77455 -0.096218 0.15055 0.40654 0.47132 -0.043477 0.018865 -0.31835 0.0021327 0.51416 0.07266 0.86377 0.39094 -0.2941 0.022928 2.9991 -0.14775 -0.48026 -0.46537 -0.28892 -0.28702 -0.78647 0.21987 0.23957 0.2389 0.04237 0.05836 0.11709 -0.18796 -0.31004 -0.64738 -0.7185 0.33694 0.3713 0.6525 -0.48662 0.093115 0.068172 -0.064165 0.0067802 0.8213 -0.46428 0.052333 -0.054842 -0.81224 0.12655 -0.1431 0.53736 -0.10751 -0.1201 -0.13545 0.20551 -0.25494 -0.14893 0.090701 0.36655 -0.20965 0.673 0.51765 -0.35084 -0.47291 0.31541 -0.19238 -0.02999 0.018858 -0.40037 0.0066421 0.12526 0.097123 -0.10354 0.027577 0.073137 0.22532 -0.41189 0.047902 0.11876 -0.57981 0.54385 0.33422 0.3453 0.2162 -0.69258 -0.13744 -0.59278 -0.054606 -0.10773 0.79549 -0.025879 -0.116 0.4545 0.070413 -0.49586 -0.35715 -0.28674 0.5773 -0.81279 0.019403 0.091408 0.13133 0.34139 0.52689 0.64284 -0.26375 -0.018898 -0.51385 -0.062924 0.16246 0.48888 0.72696 0.49494 -0.45197 -0.25742 0.0047182 -0.91796 0.46416 0.1966 0.67564 -0.080587 0.12588 -1.2989 -0.02176 0.4114 0.41177 -0.60598 0.10907 0.0048411 0.36911 -0.35354 0.50438 0.43354 -0.60223 -0.070002 -0.59426 0.081687 -0.74034 -0.071562 -0.14978 -0.47965 1.3329 0.52734 -0.14646 -0.18742 0.23384 -0.088226 -0.22079 0.42821 0.07259 -0.86941 0.065263 0.14209 -0.38875 0.62475 -0.043056 -0.1405 -0.087399 0.26025 0.18315 0.57811 -0.3948 0.84753 0.25191 0.15239 -0.86611 0.56031 -0.13038 0.31795 0.089552 0.24 0.11417 0.13804 -0.47975 -0.49307 -0.65965 -0.03232 0.99141 0.49788 -0.43471 -0.082005 -0.22052 -0.069465 -0.025023 0.40196 -0.22087 0.1288 -0.11603 0.21029 -0.37609 -0.065688 0.72272 0.11403 -0.08957 -0.34873 -0.47252 0.85348\n",
            "not 0.34303 0.4082 -0.023317 -0.36093 0.0526 0.28925 -0.72928 0.077745 0.25907 0.20004 0.14167 0.49461 -0.043323 -0.17258 0.071147 0.26755 -0.17498 0.81793 0.16388 -0.43131 -0.10978 3.3862 -0.39972 0.079416 0.00044842 0.025372 -0.066779 -0.073348 0.11878 -0.071623 -0.095796 -0.11912 0.13945 0.081686 0.11199 -0.379 -0.86427 -0.65059 0.0072629 0.11515 0.13784 -0.37365 -0.023701 0.31684 -0.22221 0.0094901 0.48885 -0.23512 0.20877 -0.36594 -0.086444 -0.19801 -0.43175 0.22803 0.32309 -0.20011 0.1592 -0.27653 -0.043781 0.30648 0.21574 0.26831 -0.12455 -0.11471 0.29235 -0.041827 -0.27627 0.6043 0.1427 0.5277 0.87699 0.22292 -0.13668 0.13928 -0.46867 -0.13543 -0.47535 -0.46317 0.01747 -0.231 0.14377 -0.15767 0.26873 0.24767 0.24199 -0.12111 -0.40109 -0.5547 0.025637 -1.227 0.25114 0.35073 0.62196 -0.19648 -0.27999 0.09606 -0.082684 -0.014249 -0.099184 -0.11603 0.35344 -0.033989 -0.060309 -0.48616 0.14479 -0.17586 -0.36172 1.2432 -0.4364 -0.16122 -0.13308 -0.34845 0.21167 0.097091 0.23652 0.027138 0.29117 -0.36449 -0.38529 -0.17665 0.37197 0.14412 0.40894 -0.11261 0.097247 -0.24356 -0.018665 0.16607 0.3411 -0.28714 -0.28679 0.49481 0.40374 -0.39017 0.35375 0.12035 -0.065398 -0.16071 -0.044542 -0.28337 0.042688 0.027212 0.37139 -0.30543 1.4214 0.53121 -0.46548 -0.19737 -0.0054895 -0.18203 0.11912 0.42438 -0.40208 0.058662 0.10283 -0.30155 -0.33827 0.34796 -0.082353 0.51862 -0.29775 0.14422 0.44026 -0.123 -0.23571 0.17797 0.11558 0.18801 -0.30945 0.48821 0.1476 0.40829 0.19013 -0.13821 0.333 0.011581 -0.57089 0.30526 0.20618 0.17889 1.2769 -0.11154 -0.47002 -0.12611 -0.20999 -0.013965 -0.078315 0.15576 0.099716 0.27449 -0.36542 0.24097 0.11508 -0.032185 0.18049 -0.028734 0.13449 0.1724 0.031143 0.031783\n",
            "this 0.39086 0.65528 0.064706 -0.33366 0.18502 -0.027321 -0.3878 -0.15081 0.39917 -0.30206 0.23819 0.45941 -0.023606 -0.043237 0.54309 -0.085014 -0.044168 0.66163 -0.39539 -0.27537 0.37465 3.0274 -0.085225 0.1731 0.58574 -0.36105 0.18828 0.41495 0.13081 -0.039031 -0.24917 -0.16286 0.012653 -0.0098054 -0.11815 -0.16429 -0.90413 -0.57109 0.026838 -0.43601 -0.15484 -0.37619 0.24899 0.51744 0.0009744 0.12833 0.24256 0.26005 0.050365 -0.016651 0.091362 -0.31346 -0.0078254 0.72088 0.1415 -0.0050633 -0.24204 -0.39191 -0.058966 -0.053058 0.25604 0.074284 -0.23051 -0.54815 -0.22384 -0.031049 0.019959 0.17193 -0.054222 0.033631 0.39632 0.24702 -0.14935 0.42653 -0.27151 0.28648 -0.46361 -0.21448 -0.46598 0.057568 -0.12724 -0.14651 -0.36591 0.34369 0.05271 -0.018639 -0.46642 -0.49551 0.62577 -0.64458 0.41497 0.15695 0.5569 0.074682 -0.59488 0.15163 0.0050693 -0.11666 0.010334 -0.21172 -0.19726 0.25814 0.16371 0.10557 -0.0063813 0.12384 -0.23964 0.99755 -0.78864 0.25616 0.28623 -0.45224 -0.0022179 0.057452 0.041398 0.09977 0.027042 -0.088172 -0.29811 -0.026336 0.069132 0.23899 0.35541 -0.063479 0.0059764 -0.21982 0.38767 0.1966 -0.027814 -0.088787 -0.19875 0.14134 0.22949 -0.27561 0.13077 0.41609 -0.10151 -0.077741 -0.16479 0.043119 -0.24528 0.21869 0.095889 -0.32395 1.5937 0.31002 -0.058686 -0.45488 0.077925 0.17054 0.0018438 0.71656 -0.42026 0.07127 0.51768 -0.21712 -0.2484 0.22494 0.069718 -0.38438 0.19313 -0.1105 -0.10447 -0.32604 -0.26355 0.073983 -0.27133 0.084472 -0.58727 0.53549 -0.059486 0.22041 0.64939 -0.11922 -0.0081812 -0.063136 -0.15009 -0.096871 -0.27551 0.23581 1.8095 -0.35952 -0.026458 0.47649 -0.18462 0.057494 -0.11701 0.23265 0.043931 0.32839 0.084436 0.051592 0.021732 0.10135 0.075084 -0.23 -0.20108 0.3865 0.052221 -0.22646\n",
            "who 0.075467 -0.29236 -0.26037 -0.28167 0.16097 -0.19472 -0.28206 0.49141 -0.0041119 0.095879 0.33396 0.016874 0.20616 -0.15743 -0.16138 0.21538 -0.14836 0.02546 -0.43681 -0.063661 0.55261 3.0819 -0.11784 -0.46131 -0.27609 0.20948 -0.20544 -0.57155 0.33448 0.15913 0.0025436 0.18004 0.13472 -0.097404 0.35537 -0.47428 -0.79257 -0.54418 0.0243 0.63599 0.12337 -0.12913 -0.26565 -0.24957 -0.52199 -0.40523 0.48403 0.018373 0.23039 0.062138 -0.19292 0.29506 -0.35793 0.16702 0.31868 -0.36054 -0.10978 -0.15632 0.45921 0.096475 -0.377 -0.077615 -0.48899 0.20575 0.50543 0.053419 -0.25978 0.51042 0.097521 0.32606 0.14354 0.0022715 0.48615 0.46938 -0.41124 -0.17148 -0.39744 -0.28901 -0.17756 0.037001 0.3483 0.15934 -0.74281 0.18897 0.043685 0.57208 -0.67016 -0.043947 -0.28336 -0.31996 -0.20404 -0.087898 -0.15724 0.021818 -0.56757 0.63296 -0.10097 -0.065576 0.0058269 0.033035 0.39783 -0.31166 -0.61089 0.27559 0.10008 -0.4199 0.006356 1.8717 0.31473 -0.36004 0.81384 -0.2171 -0.018459 -0.22632 0.14585 -0.1435 -0.041424 0.55974 -0.66752 -0.21959 0.19011 0.33015 0.6129 0.46771 0.42026 -0.52819 0.023165 0.03291 0.47306 0.014006 -0.17396 -0.44362 0.41377 -0.20679 0.39283 0.30211 0.073134 0.042164 -0.9271 -0.47614 0.2431 -0.13379 -0.22238 -0.041457 1.585 0.37481 0.025994 -0.24272 0.30578 0.14687 0.11666 -0.029418 -0.078339 -0.22512 0.13315 -0.064842 -0.28687 -0.01056 -0.34668 0.042145 -0.60041 0.82481 0.31022 0.16489 -0.072921 0.19394 -0.098498 -0.020383 -0.40909 -0.10404 0.19169 -0.15969 0.38026 0.62802 0.2595 -0.33367 -0.73333 -0.40743 0.68423 -0.066338 0.50436 -0.28983 -0.39086 -0.045931 -0.26624 -0.1677 -0.15037 0.14828 -0.28143 -0.17087 -0.25576 -0.056283 -0.1665 0.35106 0.041032 0.27311 0.03002 0.16465 -0.084189 0.057506\n",
            "they 0.0528 0.13495 -0.38214 -0.27999 -0.38392 -0.084598 -0.37277 0.10046 -0.023454 0.71256 0.024259 0.2814 0.010209 -0.19417 -0.30018 0.2074 -0.18105 0.71611 -0.11311 -0.26412 0.17681 3.2366 -0.2329 -0.07999 0.13482 -0.22448 -0.11799 -0.092002 0.23552 -0.12608 0.12557 -0.21536 0.12587 0.049804 0.024991 -0.55934 -0.93924 -0.51797 0.42125 0.34652 0.19897 -0.014204 0.17652 0.43155 -0.38901 0.032722 0.95275 -0.24641 0.12699 0.24171 -0.2495 0.13663 -0.58702 0.53192 0.25364 -0.44631 0.071339 -0.1072 0.016232 0.28356 0.25355 0.36077 -0.066849 0.22595 0.26663 0.1958 -0.21102 0.39934 -0.0066386 0.095334 0.46205 0.028948 0.20202 0.1217 -0.1758 -0.24526 -0.29105 0.153 -0.081641 -0.1527 -0.061132 0.33011 -0.27052 0.24315 0.31077 0.24527 -0.55383 -0.56974 -0.055326 -1.1106 0.23658 0.092638 0.73168 0.085777 -0.24735 0.2301 0.049224 -0.10027 -0.12215 -0.32324 0.45269 -0.2575 -0.16278 -0.18948 0.23016 0.33619 0.11044 1.0879 -0.48341 -0.24421 -0.11329 -0.028835 0.19768 0.31868 0.14758 0.1623 0.071596 0.032118 0.072414 -0.16726 0.74261 0.12729 0.3097 -0.32765 0.12688 -0.69808 0.20057 0.2493 0.49528 -0.4856 -0.46447 0.41582 0.47338 -0.38178 0.4538 0.18398 -0.12377 -0.28023 -0.22348 -0.11058 -0.26895 -0.13358 0.21927 -0.46339 1.4292 0.67536 -0.17342 -0.46714 0.0090229 0.099559 0.15438 0.44203 -0.49867 -0.061944 -0.0033505 -0.17547 -0.1701 0.34289 -0.093336 0.28919 -0.32519 0.13184 0.0011452 -0.084836 -0.26536 0.46792 0.23974 0.044068 -0.75486 0.30871 0.10976 0.039385 0.48202 0.053616 0.43554 0.057253 -0.56428 -0.33534 -0.032656 0.19587 1.2662 -0.3715 -0.74673 -0.19089 -0.2307 0.094298 -0.018306 0.055102 -0.028414 0.27891 -0.22275 0.25638 0.064459 0.031974 0.19601 0.004318 0.043765 0.42737 -0.20698 0.44511\n",
            "had -0.33133 -0.40435 -0.40979 -0.66988 -0.39441 0.076152 -0.5469 -0.43187 0.1011 0.25393 -0.0082775 0.2753 0.27533 -0.19908 0.0090264 0.52971 -0.43718 0.53835 0.17387 -0.30025 0.41326 3.0783 -0.20477 -0.20203 -0.50297 -0.036105 -0.34391 -0.64871 0.14952 -0.012018 -0.29569 -0.058841 0.24514 -0.56065 0.04286 -0.29726 -0.69872 -0.56878 -0.25978 -0.00074102 -0.0052548 -0.56586 -0.3212 0.22525 -0.24986 -0.25824 0.38695 0.29496 -0.19407 0.037635 -0.26758 0.00034218 -0.41116 0.60466 0.14315 -0.30094 -0.20945 0.16205 -0.067517 -0.071269 -0.15515 0.052827 -0.7435 -0.01191 0.51966 -0.41033 -0.88799 -0.084164 -0.13655 -0.033366 -0.14022 -0.43091 0.4342 -0.064316 0.14283 -0.22543 0.10338 -0.10323 -0.09803 -0.22458 0.31746 -0.10338 -0.542 0.20488 0.20894 0.12 -0.54838 -0.40395 -0.24804 -0.47192 0.19544 0.15752 0.67191 -0.053668 -0.46669 0.41288 -0.019483 0.016923 -0.22841 -0.038222 0.19118 -0.4349 -0.12291 0.12518 -0.12883 -0.049208 0.43689 0.83234 -0.37425 -0.77385 0.062152 -0.26202 -0.27913 0.074301 0.72685 0.39949 -0.32464 -0.028547 -0.051718 -0.088351 0.26516 0.19021 0.44938 0.16984 0.47906 -0.77419 -0.052722 -0.021962 0.30443 -0.25446 -0.0083144 -0.17947 0.23632 -0.01714 0.62515 0.61452 -0.52059 -0.013276 -0.54876 -0.08088 -0.21286 0.034279 -0.089888 -0.603 1.629 0.61993 0.11693 -0.6153 0.31789 -0.21176 -0.3541 -0.12374 0.0025922 -0.11021 -0.1289 -0.31611 -0.3962 0.27534 0.0079809 -0.023629 -0.36958 0.26555 0.29601 0.20313 -0.4082 0.79111 0.16731 0.048476 -0.57412 0.47241 0.56614 0.034783 0.35265 0.1397 0.3506 0.065326 -0.59825 -0.39489 0.28898 -0.039813 0.85962 0.45943 -0.4968 0.030587 -0.56187 -0.33846 -0.43946 0.28178 0.11534 0.38179 0.12868 0.17615 -0.40563 0.12364 0.29055 0.083565 0.10535 0.32032 -0.23686 0.16433\n",
            "i 0.26805 0.36032 -0.332 -0.54642 -0.50451 -0.013461 -0.80432 -0.24214 0.53736 0.77581 -0.32554 0.483 0.84265 0.3778 -0.14767 0.53192 -0.70518 0.44037 0.75035 -0.18171 0.70139 2.9383 0.045612 -0.21176 0.19947 -0.48175 -0.25815 0.462 -0.0056841 -0.30563 -0.57541 -0.019527 -0.13751 -0.5945 -0.38216 -0.13541 -0.66444 -0.23028 -0.055466 0.38421 -0.16888 0.051462 -0.28293 0.45076 -0.36464 0.36101 1.0935 -0.11947 0.049729 0.048765 0.48944 -0.00033138 0.16365 0.49743 0.33814 0.01557 0.25762 -0.58483 -0.55821 -0.29092 0.23611 -0.28951 -0.31919 0.065705 -0.31602 -0.12054 -0.77942 0.60136 0.4416 -0.027946 0.73821 -0.31318 -0.053737 -0.26919 -0.56458 -0.65164 -1.2298 -0.05043 -0.72749 0.085426 -0.14811 -0.1508 -0.45213 0.34224 0.099421 -0.38825 -0.26387 -0.25937 -0.045955 -1.5518 0.27701 -0.50155 0.63821 -0.21799 -0.15459 0.2047 0.37607 0.1383 -0.59114 -0.20036 -0.01763 -0.29715 0.012323 -0.1147 0.82837 0.10221 -0.21023 1.4215 -0.57118 0.34696 0.1075 0.20036 0.11781 -0.16939 -0.066335 -0.094572 -0.21243 -0.063982 -0.30773 0.1412 0.55169 0.14343 0.74784 -0.31253 -0.1061 -0.33361 0.02888 -0.04148 0.58897 -0.84928 -0.36634 0.040954 0.083578 0.20159 -0.31628 0.32837 0.078545 0.068703 -0.32559 -0.58249 -0.20688 -0.49981 -0.09869 -0.55841 2.0955 0.61811 0.23829 -0.52405 -0.1331 -0.0096439 0.63668 0.92328 -0.73654 0.20892 0.064937 -0.16934 -0.061282 -0.13634 0.15841 0.50026 -0.2762 0.22532 0.08673 -0.056935 -0.45413 0.12981 -0.01702 0.46354 -0.42211 -0.072322 -0.061887 -0.40143 0.66137 -0.046212 0.27799 0.13435 -0.77289 -0.21018 1.02 0.44495 1.1312 -0.1758 -0.67577 0.28609 -0.6077 -0.65499 0.038634 0.48288 0.35732 0.24206 -0.18247 -0.27803 -0.060281 -0.066602 -0.055558 -0.19829 0.53632 0.17769 0.22362 0.014241\n",
            "which -0.010102 0.21802 -0.11611 0.094425 0.22263 -0.15089 -0.2899 0.025147 -0.097949 -0.40939 -0.11947 0.39364 -0.096967 -0.0098863 0.086387 -0.073782 -0.059744 0.46418 -0.43415 -0.19751 0.37536 3.1439 -0.13073 -0.2506 0.11124 -0.11375 0.034088 -0.01673 -0.049775 -0.020154 0.14205 -0.10886 -0.22264 -0.23937 -0.24235 -0.29477 -1.0544 -0.54634 -0.13587 -0.27457 0.058653 -0.28976 0.13347 0.37079 -0.021389 0.11285 0.37122 0.036881 -0.18092 0.24568 -0.16806 -0.35626 0.0092038 0.080702 0.35622 0.061029 -0.3249 0.28941 -0.0217 0.26788 -0.055277 -0.11741 -0.14421 -0.038636 -0.051506 0.096784 -0.38684 -0.13169 -0.03937 -0.032725 0.24728 0.32124 -0.066242 0.32483 -0.036347 0.47052 0.29366 -0.31134 -0.13982 -0.33421 0.063909 -0.23926 -0.070224 0.070027 0.17949 -0.05135 -0.58551 -0.19029 0.62491 -0.52575 0.30292 0.44883 0.4933 -0.16261 -0.29332 0.33719 0.17523 -0.34721 -0.018518 -0.62768 -0.19205 0.73651 0.22107 0.61762 -0.040511 -0.30281 -0.043487 1.0085 -0.069434 -0.25476 0.069975 -0.43039 -0.2166 0.07103 0.30963 0.12642 -0.25129 -0.071293 0.0084477 -0.091257 0.035578 0.28844 -0.12555 0.31694 0.17902 -0.55618 0.53784 -0.030637 0.059911 0.044141 -0.12445 0.022116 0.20851 -0.54222 0.12473 0.070388 -0.22374 -0.36096 -0.2478 0.28675 0.12382 0.29722 0.091288 -0.48263 1.1476 0.031731 -0.24172 -0.44882 0.079954 0.17569 -0.011607 -0.05039 0.16242 -0.15851 0.573 -0.36627 -0.47706 0.36065 0.010719 -0.41937 -0.055661 -0.13646 -0.047802 0.063818 0.12402 0.18626 -0.0054635 0.13583 -0.067232 0.72871 -0.059966 0.43775 0.35875 -0.12261 -0.003121 0.38247 -0.16289 -0.038826 -0.22237 -0.066314 1.6452 -0.19555 -0.062446 0.075431 0.19036 -0.030622 -0.36349 -0.031064 0.41331 0.204 0.0035158 0.10664 -0.32209 0.093381 0.14072 0.14195 -0.081597 0.48054 -0.021233 -0.061626\n",
            "will 0.39888 0.70125 0.11926 0.06326 0.51438 0.16009 -0.13237 -0.32747 0.17804 0.37289 0.029447 0.061814 -0.079392 -0.14113 0.55745 -0.27201 -0.061969 0.76481 -0.22171 -0.33719 0.11137 3.3747 -0.69309 0.056095 0.18097 0.076254 -0.024701 0.14218 -0.33273 -0.0094807 0.109 -0.40391 -0.48332 -0.055084 0.070684 -0.18003 -0.61999 -0.50348 0.21388 0.36021 0.24029 0.24924 0.19752 0.38297 -0.32588 0.57685 0.39968 -0.60984 -0.21872 -0.42872 0.25839 -0.20533 -0.83724 0.3489 0.74864 -0.34499 -0.05192 0.002992 0.24886 0.34007 0.67558 0.51091 0.26494 -0.29127 0.057068 0.33976 -0.18983 0.69566 -0.27613 0.49433 0.93853 0.26995 0.46341 0.61545 -0.23328 0.52893 -0.77243 -0.307 -0.15599 -0.058136 -0.24201 -0.33967 -0.10576 -0.20146 -0.20211 -0.15894 -0.25755 -0.21891 0.16461 -1.0524 0.52408 -0.11303 0.21722 0.14812 -0.20262 0.28706 -0.20033 -0.099344 -0.15847 -0.75563 0.2574 -0.045007 -0.39608 0.28444 0.1232 0.0073429 -0.44655 1.713 -0.68322 -0.38852 -0.10284 -0.4288 0.00061036 -0.18998 -0.15584 -0.23804 0.063784 0.024879 -0.16019 -0.037399 0.29923 -0.36701 0.43798 0.055086 -0.22622 -0.33473 0.14521 0.10772 0.13781 0.27754 -0.15732 0.16098 -0.069611 -0.364 -0.084364 0.49589 0.40904 -0.16848 -0.12284 -0.030629 -0.081816 -0.004539 0.52388 0.1847 0.90678 0.35901 -0.59856 0.2148 -0.12821 0.22804 0.60167 0.24951 0.086361 0.33798 0.047767 -0.33821 -0.56883 0.37426 -0.00035053 -0.052105 -0.46565 0.086763 0.39697 -0.46589 0.53298 0.35998 -0.18722 -0.49917 0.11483 0.58261 0.32118 0.13101 0.51832 -0.026715 0.028877 0.57583 -0.62759 -0.50606 -0.21902 -0.083793 1.3803 -0.55532 -0.063694 -0.37348 0.0089405 0.20293 -0.12174 0.046872 -0.23435 0.38024 -0.36358 0.2508 -0.29805 -0.022182 -0.42856 0.07994 0.25939 0.12281 -0.18703 0.33635\n",
            "their -0.13141 0.15876 -0.017485 -0.20288 -0.44226 0.30734 0.095026 0.17375 -0.78641 0.9432 -0.36904 0.34454 -0.22795 0.2727 0.21195 0.12715 -0.032141 0.73053 -0.6157 0.10222 0.18379 3.3705 0.30083 -0.12823 0.43607 0.024522 -0.091563 -0.038766 0.10678 -0.067084 0.085409 -0.36925 0.24882 0.15597 -0.17784 -0.315 -0.72439 -0.11631 0.2359 0.12807 0.41887 -0.037921 0.41881 0.34063 -0.27459 0.20094 0.74185 -0.086798 0.034259 0.1803 -0.47086 0.070865 -0.4269 0.39622 0.033827 -0.41116 0.31848 0.33128 0.39658 0.28785 0.48371 0.28473 -0.82997 -0.059885 -0.16258 0.36143 0.10905 0.22934 0.26223 -0.15127 0.51366 0.1738 0.16682 0.16971 0.074594 0.41107 -0.68597 0.020028 0.097024 0.0050171 -0.16779 0.49316 -0.44981 -0.23984 0.59005 0.41795 -0.23865 -0.82775 0.56036 -0.96278 0.17704 0.36098 0.37056 0.5259 -0.16342 -0.18727 -0.15578 -0.099543 0.30891 0.0080567 0.06057 -0.45867 -0.55696 -0.44324 -0.54955 -0.0003064 0.62279 0.80639 -0.56223 -0.60223 -0.45098 -0.093732 -0.34668 0.31711 0.011749 0.56686 0.2867 0.26218 0.41922 -0.73657 0.8289 0.047568 0.18177 -0.27709 0.58642 -0.61104 0.37388 0.13618 0.5492 -0.16357 -0.52804 0.55809 0.75914 -0.33952 0.20604 0.62033 -0.19575 -0.32656 -0.19245 -0.10594 -0.5948 0.15138 0.53111 0.10331 1.389 0.43868 -0.13614 -0.24683 -0.35052 0.22165 -0.28681 0.063359 -0.3499 -0.098917 -0.066194 0.34811 -0.2275 0.28617 -0.041046 0.20754 0.56042 -0.21571 -0.15555 0.057517 0.29488 0.74649 0.26841 -0.3718 -0.4757 0.94085 0.084215 0.028106 0.53514 0.37443 0.046782 0.31346 -0.91763 -0.78156 -0.30839 0.17815 0.82101 -0.28097 -0.30477 -0.34873 -0.062123 0.18412 0.11916 -0.19294 -0.078361 0.45947 -0.018604 0.28618 0.079301 0.21807 0.30015 -0.7117 0.59814 0.41387 -0.13368 1.1326\n",
            ": 0.43607 1.5253 -0.11532 0.33558 0.36617 0.47508 -1.0557 0.22505 0.13888 0.30744 0.061002 0.57085 0.33576 -0.36794 0.09698 0.30903 -0.32093 0.24723 -0.45797 -0.19067 0.45986 2.7278 -0.17021 -0.31093 0.7966 0.43513 -0.34839 -0.31818 0.11543 0.32658 0.05071 0.25628 -0.31691 -0.095136 0.25616 0.2653 -0.18388 -0.0027588 -0.054422 -0.11367 -0.041656 -0.3647 -0.21316 -0.16306 -0.086475 0.42307 0.70147 -0.23672 0.21132 -0.35152 0.015901 -0.16657 0.35677 1.0176 -0.3804 0.5326 -0.040083 0.028004 0.72222 -0.033309 0.4545 0.32546 -0.3144 -0.30862 -0.32247 -0.74162 0.62982 0.18419 0.83641 0.057143 0.044626 0.17743 -0.47078 0.14666 -0.084274 0.47763 -0.41287 -0.051518 -0.21909 -0.51406 -0.069663 -0.18053 0.0078746 0.2968 -0.39151 -0.26965 0.039495 -0.15209 0.32589 -0.78447 0.18729 -0.16083 -0.23359 -0.26732 -0.38252 -0.3905 -0.19505 -0.6416 -0.050227 -0.0032549 -0.18282 0.62015 0.32872 0.28282 0.42784 -0.30648 0.090426 0.86602 -0.099241 0.4642 -0.38172 -0.5121 0.090157 0.22813 -0.8707 -0.093342 -0.068269 1.0051 -0.80065 -0.24277 -0.075621 0.022091 0.46845 -0.24261 -0.0013757 -0.65258 -0.28057 -0.135 0.37232 -0.38339 -0.0068095 -0.4204 -0.076423 -0.62309 -0.44962 -0.50501 -0.24561 -0.18713 -0.15956 -0.3706 0.018231 0.40244 0.31071 -0.08613 1.2455 0.4563 -0.218 0.1214 -0.39635 0.048033 0.33248 0.5421 -0.043864 -0.030044 0.95307 0.090684 0.023287 -0.61533 0.86688 -0.63448 0.19418 -0.045748 0.25649 -0.22704 -0.0080709 -0.21165 0.058644 0.23489 -0.040449 0.15013 -0.25673 0.47524 0.57577 -0.22237 -0.39381 0.27329 -0.15756 0.21529 -0.048329 -0.18216 0.93616 -0.51352 -0.142 0.23171 -0.14501 -1.0625 0.197 0.21344 0.060432 0.072564 -0.52779 0.29842 0.01568 -0.1628 -0.018805 -0.3555 -0.2302 -0.26176 0.23047 0.53547\n",
            "or 0.39371 0.29692 -0.055505 -0.42415 0.15598 0.17443 -0.55871 0.13289 -0.38696 0.088451 -0.083456 0.27341 0.83973 -0.17802 0.22857 0.14723 -0.16817 0.36687 0.49227 -0.24719 -0.33 3.3804 -0.3564 0.10359 0.0017225 -0.23269 -0.1874 0.18002 0.019888 0.38127 0.49936 0.1517 -0.24709 0.05025 0.031217 -0.11531 -0.16838 -0.67034 0.033358 0.08497 0.35612 -0.4514 0.387 -0.064141 0.00087327 0.090046 0.32416 -0.15641 0.17771 0.65094 -0.35035 -0.12522 -0.15817 1.1012 0.45614 0.19717 -0.034508 -0.24459 0.17872 0.30991 -0.14115 -0.15732 0.021527 0.05545 -0.28058 0.074175 -0.15611 0.49479 0.4344 -0.08328 0.68759 0.30234 -0.23673 0.00061976 -0.23533 0.067497 -0.34476 -0.91535 0.29406 -0.30569 0.29021 -0.084701 0.23438 -0.10612 0.13213 -0.33845 -0.13355 -0.21788 0.37375 -0.22914 -0.070838 0.30368 0.77959 0.44843 0.41491 0.15437 -0.065115 -0.426 -0.60235 0.36726 -0.29803 -0.24988 -0.00932 0.3837 -0.07166 -0.27968 -0.16034 1.0234 0.54227 -0.085608 0.075372 -0.042344 0.21207 0.49954 0.48436 -0.27112 -0.099989 0.22033 -0.11599 -0.26383 0.5123 0.13532 0.27543 0.19072 0.37891 -0.58298 0.40391 0.75624 -0.030237 -0.34744 -0.66609 0.65409 0.14479 -0.4989 0.41207 -0.097382 -0.20724 -0.30268 -0.27746 -0.53426 0.28689 -0.0043087 0.41635 -0.54533 0.91706 -0.21564 -0.072771 0.053154 -0.050122 0.067288 0.18909 0.6293 -0.50334 -0.28212 0.15207 0.41002 -0.04986 0.3165 0.043134 0.11189 0.41768 0.083279 -0.058825 -0.021373 -0.3267 -0.013466 0.18741 0.41868 -0.44251 0.8394 -0.44145 0.0628 0.030774 0.1874 0.37959 0.78608 0.21162 0.22149 0.080478 0.19913 1.4492 -0.029001 -0.24492 0.07548 0.21266 -0.48532 -0.36164 0.02686 -0.14581 0.16431 -0.52819 -0.11787 0.068606 -0.059172 -0.098025 -0.11607 0.11121 -0.097836 -0.24718 0.53283\n",
            "its -0.10339 0.18471 0.043204 -0.24525 0.19394 0.17521 0.060548 -0.27301 -0.4077 0.0093252 0.012492 0.73815 -0.499 0.12441 0.70322 0.034734 0.3354 0.41743 -0.3636 -0.4003 0.33192 3.4232 -0.10131 -0.38188 0.2958 0.28383 -0.27196 0.047931 -0.33513 -0.030201 -0.17247 -0.58169 0.13631 -0.39935 -0.29702 -0.067258 -1.0137 -0.15347 -0.34336 -0.11083 0.1943 -0.28163 0.42254 0.28635 -0.19607 0.2887 0.20889 0.33143 -0.061683 0.10813 -0.040909 -0.562 -0.020148 -0.051732 0.3895 0.0089896 -0.35965 0.03491 -0.10953 0.55956 0.44641 -0.12711 -0.61417 -0.57522 0.068125 0.37379 -0.3002 -0.20929 0.28607 0.012948 0.53918 0.31671 0.089335 0.38664 -0.057177 1.3366 -0.13351 -0.25482 -0.5198 -0.25748 -0.1444 -0.36936 0.031118 -0.63958 0.34118 -0.04983 -0.010157 -0.26288 1.301 -0.64787 0.3967 0.6181 0.53309 -0.12836 -0.4503 -0.59601 -0.088231 0.063636 0.24162 -0.14481 0.054455 0.28427 0.065261 0.19291 -0.65832 -0.16734 0.27911 0.96587 -0.58019 -0.52491 -0.31848 -0.18041 -0.45306 0.26028 0.14286 -0.081242 0.14845 0.19502 0.28867 -0.40991 0.15066 -0.040684 -0.1466 -0.26663 0.37198 -0.35824 0.34417 -0.083105 0.085887 -0.50557 -0.47061 0.083528 0.46899 -0.48495 -0.11422 0.61943 -0.11432 -0.0060738 0.22784 -0.08393 -0.49879 0.10323 0.66516 0.32128 0.96843 -0.10717 -0.027749 -0.39305 0.080111 -0.04109 0.050331 -0.086906 0.3065 0.19309 0.7372 -0.033072 -0.94 0.38494 -0.25423 -0.33907 0.98746 -0.90252 -0.39727 0.26129 0.15362 0.22158 -0.031911 -0.38738 -0.087088 1.309 0.468 0.22908 0.015762 -0.33388 -0.14677 0.092103 -0.18436 -0.48968 -0.36513 0.067201 1.0395 0.0021241 -0.08364 -0.12724 0.12281 0.30484 -0.36953 0.11034 0.25424 0.55825 0.18224 0.3173 -0.27697 0.22985 0.23359 -0.5295 0.18601 0.4333 0.34661 0.68612\n",
            "one -0.052065 0.38853 -0.2903 -0.23361 -0.031615 0.02306 -0.44796 0.12344 -0.00065561 -0.40855 0.12563 0.26825 0.31878 0.35943 0.13036 -0.11321 -0.1751 -0.046895 -0.22966 -0.19651 0.14041 3.385 0.47921 -0.56123 0.26515 -0.43217 -0.064114 -0.3619 -0.079262 -0.24169 0.001449 0.17877 0.22364 0.12274 -0.22854 -0.062958 -0.65682 -0.50515 -0.43035 -0.14219 -0.3962 -0.17886 0.19574 0.32614 -0.41829 0.19406 0.29966 -0.028482 -0.18621 0.06562 -0.15799 -0.042951 0.14633 0.53079 0.40991 0.38414 -0.036313 -0.13173 -0.10549 0.40602 -0.08874 0.093583 -0.58678 -0.027815 0.025363 0.18599 -0.040163 0.09522 -0.27638 -0.016227 0.3152 -0.25334 0.12982 0.24421 -0.13057 0.57597 -0.38969 -0.20226 -0.14958 -0.30165 0.16215 -0.15015 -0.17585 0.045831 0.034862 0.27937 -0.55784 -0.20616 0.11439 -0.60646 0.092934 0.29043 0.15525 -0.15245 0.074649 0.22843 0.17377 -0.056912 0.043463 -0.14503 0.40486 0.10639 0.058786 0.072448 0.0037798 -0.3073 -0.069552 1.2582 -0.21731 0.35402 0.33702 -0.48083 -0.086752 0.019423 -0.26285 0.11025 -0.30929 -0.13035 -0.42402 -0.15526 0.30695 0.15632 0.17764 -0.026123 -0.02286 -0.70615 0.058339 0.077275 0.42823 -0.37925 -0.53259 0.095939 0.30351 -0.43833 -0.16216 0.12578 -0.2981 -0.32538 -0.41167 -0.14343 -0.17599 0.34195 0.094111 -0.2833 1.5704 0.1404 0.23071 -0.047444 0.32836 0.063056 0.27249 0.3028 -0.23535 0.20596 0.30351 -0.057411 0.050291 0.10199 0.19441 -0.22707 0.11929 0.149 0.38247 -0.33656 -0.14875 0.041245 -0.16417 0.093058 -0.33421 0.1562 -0.0049256 0.10524 0.44417 0.23784 0.037595 -0.027932 -0.27269 -0.29546 0.12687 -0.067818 1.1804 -0.13686 -0.096533 0.24374 -0.16459 -0.19767 -0.17043 0.61455 -0.17662 0.20786 -0.14721 -0.024145 0.20276 0.24058 0.2837 -0.031417 -0.084154 0.17991 -0.042514 0.15064\n",
            "after -0.53799 0.31267 -0.50511 -0.65812 -0.31094 0.22206 -0.064532 -0.42085 0.03518 0.84507 0.22464 0.092852 0.34531 -0.044619 0.40649 -0.043563 -0.15766 0.25347 0.11048 -0.37443 0.33254 3.3128 0.20996 -0.25557 0.30514 0.29894 -0.39617 0.41721 0.25051 0.079694 0.14117 -0.31772 0.12135 -0.19561 0.032901 -0.19729 -0.78267 -0.19376 -0.38766 0.18137 -0.27011 -0.1357 -0.13148 0.48091 0.24991 0.49448 0.07643 0.5448 -0.22966 0.34264 -0.47659 0.062821 -0.27348 0.53723 -0.23225 0.00042934 -0.14653 -0.018177 -0.27076 0.18445 0.042967 -0.38254 -0.23869 -0.091224 0.15105 -0.41373 0.058216 -0.22239 0.014404 0.21518 -0.14217 -0.2822 0.43021 0.2651 0.3883 0.85756 -0.27485 0.03322 -0.26435 -0.1357 -0.020883 -0.33533 -0.25955 0.13214 0.15929 0.016671 -0.12468 -0.56269 -0.28539 -0.22327 -0.3285 0.10037 0.29106 0.50929 -0.54421 -0.29595 -0.51747 -0.07055 0.1702 0.0031873 -0.098674 -0.043157 0.038602 0.052537 -0.54306 -0.18822 0.31933 0.66711 -0.020456 -0.19699 0.26646 -0.50942 0.093716 0.36096 0.18209 0.058115 -0.3382 0.22675 -0.19314 -0.19868 -0.3835 -0.13176 -0.0086296 0.19077 0.77287 -0.67567 0.010377 0.03505 0.24526 -0.11039 -0.037213 0.17625 0.41168 -0.57605 0.57971 0.23058 0.16084 -0.21758 -0.53757 0.13485 0.0034504 0.017158 -0.16254 -0.41692 1.4061 0.5177 0.032561 -0.47582 0.14866 -0.19764 -0.26279 0.10952 -0.28563 0.16041 -0.45281 0.085154 -0.098896 -0.071334 -0.13079 -0.49895 -0.095311 0.035226 0.069358 0.54658 -0.20068 0.2151 -0.040177 0.22875 -0.28114 0.55146 0.0056952 -0.35676 0.46433 -0.21546 0.06301 0.31781 -0.31305 -0.43831 0.2806 -0.46086 1.0649 0.11891 -0.38984 0.1864 -0.24896 -0.41431 -0.2405 0.055303 -0.14437 0.13444 -0.023208 0.1781 -0.38537 0.24354 0.33829 0.16996 -0.039584 0.10233 0.026828 -0.22729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"Uma rede neural √© uma forma de simular no computador o funcionamento\n",
        "do c√©rebro humano\"\"\""
      ],
      "metadata": {
        "id": "szCnobWzhAUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokeniza√ß√£o do texto, convertendo as palavras em sequencias de inteiros\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "print(sequence_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvu8Kau-hExV",
        "outputId": "5dcdcdbd-2fb7-4792-bba3-0d1df0db9896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 4, 1, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#definindo tamanho de vocabulario a ser usado\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "seq_length = 5"
      ],
      "metadata": {
        "id": "H2f-7anlhKDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convers√£o para numpy\n",
        "sequences = []\n",
        "for i in range(seq_length, len(sequence_data)):\n",
        "    seq = sequence_data[i-seq_length:i+1]\n",
        "    sequences.append(seq)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qUpfxHzhMaJ",
        "outputId": "07fa7161-206b-4173-898a-b961019732a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  1  5]\n",
            " [ 2  3  4  1  5  6]\n",
            " [ 3  4  1  5  6  7]\n",
            " [ 4  1  5  6  7  8]\n",
            " [ 1  5  6  7  8  9]\n",
            " [ 5  6  7  8  9 10]\n",
            " [ 6  7  8  9 10 11]\n",
            " [ 7  8  9 10 11 12]\n",
            " [ 8  9 10 11 12 13]\n",
            " [ 9 10 11 12 13 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = sequences[:, :-1], sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ6AmRoDhTlP",
        "outputId": "088bf1cb-f5da-40d1-e95a-ffcb3a862888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  1]\n",
            " [ 2  3  4  1  5]\n",
            " [ 3  4  1  5  6]\n",
            " [ 4  1  5  6  7]\n",
            " [ 1  5  6  7  8]\n",
            " [ 5  6  7  8  9]\n",
            " [ 6  7  8  9 10]\n",
            " [ 7  8  9 10 11]\n",
            " [ 8  9 10 11 12]\n",
            " [ 9 10 11 12 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* One-hot encoding √© uma t√©cnica usada para representar dados categ√≥ricos como vetores bin√°rios. Cada categoria √© convertida em um vetor de bits (0s e 1s), onde apenas a posi√ß√£o correspondente √† categoria √© marcada com 1, e todas as outras posi√ß√µes s√£o 0."
      ],
      "metadata": {
        "id": "xygGNmiqmqaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#y est√° no formato One-Hot Encodding\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLRGm13mlRmZ",
        "outputId": "0b9a8b05-593a-4d49-afaf-37c951e20c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cria√ß√£o de embedding de forma que ele possa ser utilizado de forma simplificada pelo keras"
      ],
      "metadata": {
        "id": "JxXED_V4m1s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "with open(os.path.join('glove.6B', 'glove.6B.50d.txt'), encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "metadata": {
        "id": "H9JPkRqXlUbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#o objetivo dessa fun√ß√£o √© mostrar como o embedding ficou (estilo dicion√°rio)\n",
        "def print_primeiros_itens(dicionario, num_itens=5):\n",
        "    for chave, valor in list(dicionario.items())[:num_itens]:\n",
        "        print(f\"{chave}: {valor}\")\n",
        "print_primeiros_itens(embeddings_index, num_itens=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6div6lTlW6d",
        "outputId": "32c7850f-0d52-4271-bc80-d5dd3b63dfcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: [ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n",
            ",: [ 0.013441  0.23682  -0.16899   0.40951   0.63812   0.47709  -0.42852\n",
            " -0.55641  -0.364    -0.23938   0.13001  -0.063734 -0.39575  -0.48162\n",
            "  0.23291   0.090201 -0.13324   0.078639 -0.41634  -0.15428   0.10068\n",
            "  0.48891   0.31226  -0.1252   -0.037512 -1.5179    0.12612  -0.02442\n",
            " -0.042961 -0.28351   3.5416   -0.11956  -0.014533 -0.1499    0.21864\n",
            " -0.33412  -0.13872   0.31806   0.70358   0.44858  -0.080262  0.63003\n",
            "  0.32111  -0.46765   0.22786   0.36034  -0.37818  -0.56657   0.044691\n",
            "  0.30392 ]\n",
            ".: [ 1.5164e-01  3.0177e-01 -1.6763e-01  1.7684e-01  3.1719e-01  3.3973e-01\n",
            " -4.3478e-01 -3.1086e-01 -4.4999e-01 -2.9486e-01  1.6608e-01  1.1963e-01\n",
            " -4.1328e-01 -4.2353e-01  5.9868e-01  2.8825e-01 -1.1547e-01 -4.1848e-02\n",
            " -6.7989e-01 -2.5063e-01  1.8472e-01  8.6876e-02  4.6582e-01  1.5035e-02\n",
            "  4.3474e-02 -1.4671e+00 -3.0384e-01 -2.3441e-02  3.0589e-01 -2.1785e-01\n",
            "  3.7460e+00  4.2284e-03 -1.8436e-01 -4.6209e-01  9.8329e-02 -1.1907e-01\n",
            "  2.3919e-01  1.1610e-01  4.1705e-01  5.6763e-02 -6.3681e-05  6.8987e-02\n",
            "  8.7939e-02 -1.0285e-01 -1.3931e-01  2.2314e-01 -8.0803e-02 -3.5652e-01\n",
            "  1.6413e-02  1.0216e-01]\n",
            "of: [ 0.70853    0.57088   -0.4716     0.18048    0.54449    0.72603\n",
            "  0.18157   -0.52393    0.10381   -0.17566    0.078852  -0.36216\n",
            " -0.11829   -0.83336    0.11917   -0.16605    0.061555  -0.012719\n",
            " -0.56623    0.013616   0.22851   -0.14396   -0.067549  -0.38157\n",
            " -0.23698   -1.7037    -0.86692   -0.26704   -0.2589     0.1767\n",
            "  3.8676    -0.1613    -0.13273   -0.68881    0.18444    0.0052464\n",
            " -0.33874   -0.078956   0.24185    0.36576   -0.34727    0.28483\n",
            "  0.075693  -0.062178  -0.38988    0.22902   -0.21617   -0.22562\n",
            " -0.093918  -0.80375  ]\n",
            "to: [ 0.68047  -0.039263  0.30186  -0.17792   0.42962   0.032246 -0.41376\n",
            "  0.13228  -0.29847  -0.085253  0.17118   0.22419  -0.10046  -0.43653\n",
            "  0.33418   0.67846   0.057204 -0.34448  -0.42785  -0.43275   0.55963\n",
            "  0.10032   0.18677  -0.26854   0.037334 -2.0932    0.22171  -0.39868\n",
            "  0.20912  -0.55725   3.8826    0.47466  -0.95658  -0.37788   0.20869\n",
            " -0.32752   0.12751   0.088359  0.16351  -0.21634  -0.094375  0.018324\n",
            "  0.21048  -0.03088  -0.19722   0.082279 -0.09434  -0.073297 -0.064699\n",
            " -0.26044 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cria√ß√£o de matriz de embedding, cada linha/elemento corresponde a o vetor de embedding de uma palavra do vocabul√°rio\n",
        "embedding_dim = 50\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekhkF1pznP9z",
        "outputId": "744ffa8c-0bb3-4030-f6ce-95ba7f5d4c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 4.72990006e-01,  7.30139986e-02, -3.30170006e-01,\n",
              "         8.74509990e-01, -1.26599997e-01,  7.55919993e-01,\n",
              "         7.82530010e-01, -9.39459980e-01, -4.69779998e-01,\n",
              "         5.87689996e-01, -1.88079998e-01,  9.78699982e-01,\n",
              "         2.56330013e-01, -1.84029993e-02, -4.25009988e-02,\n",
              "        -3.68750006e-01, -9.51659977e-02,  9.77419972e-01,\n",
              "         4.72799987e-01,  9.32780027e-01, -3.93229991e-01,\n",
              "         5.80479980e-01,  6.55099988e-01,  7.02459991e-01,\n",
              "         2.80039996e-01, -1.67510003e-01, -1.74449999e-02,\n",
              "        -5.56190014e-02, -5.34189999e-01, -9.93030012e-01,\n",
              "        -3.54220003e-01,  8.00409973e-01, -2.37310007e-01,\n",
              "         9.09330010e-01, -7.63679966e-02, -4.16570008e-02,\n",
              "        -1.92959994e-01, -7.40760028e-01,  3.05870008e-02,\n",
              "        -5.79270013e-02,  2.21110005e-02,  8.28400016e-01,\n",
              "        -1.81319997e-01, -8.97499979e-01, -6.90210015e-02,\n",
              "        -1.36079997e-01, -1.82860002e-01, -4.10420001e-01,\n",
              "         1.10749996e+00,  8.38360012e-01],\n",
              "       [-2.65720010e-01, -1.88370004e-01, -5.64990006e-03,\n",
              "         1.05369997e+00, -1.34389997e+00, -5.03109992e-01,\n",
              "        -1.21539998e+00,  3.49099994e-01,  8.51090014e-01,\n",
              "         2.12700009e+00,  7.00200021e-01,  9.47969973e-01,\n",
              "         5.09970009e-01,  8.33509982e-01,  1.92760006e-01,\n",
              "        -1.13080001e+00, -5.95629990e-01,  3.63460004e-01,\n",
              "        -7.87540019e-01,  7.90329993e-01,  1.03699994e+00,\n",
              "         5.01980007e-01,  1.34019995e+00,  1.23909998e+00,\n",
              "         8.96520019e-01,  4.08210009e-01, -3.95570010e-01,\n",
              "        -4.18379992e-01, -6.70499980e-01,  2.97980011e-01,\n",
              "        -5.89959979e-01, -2.39089996e-01, -1.33690000e-01,\n",
              "        -1.92169994e-01, -7.84420013e-01, -8.86640012e-01,\n",
              "        -3.20870012e-01, -5.94359994e-01, -1.06750000e-02,\n",
              "         4.01250005e-01,  5.05159974e-01,  6.14320002e-02,\n",
              "        -1.38250005e+00,  3.07449996e-01, -1.85580003e+00,\n",
              "        -1.42419994e-01, -6.44860029e-01, -2.46710002e-01,\n",
              "         9.90320027e-01, -2.54269987e-01],\n",
              "       [ 9.28030014e-01,  2.90960014e-01,  6.78369999e-01,\n",
              "         1.04439998e+00, -7.25510001e-01,  2.19950008e+00,\n",
              "         8.87669981e-01, -9.47820008e-01,  6.74260020e-01,\n",
              "         2.49080002e-01,  9.57220018e-01,  1.81219995e-01,\n",
              "         6.42630011e-02,  6.43230021e-01, -1.63010001e+00,\n",
              "         9.49720025e-01, -7.36699998e-01,  1.73449993e-01,\n",
              "         6.76379979e-01,  1.00259997e-01, -3.37820016e-02,\n",
              "        -7.69710004e-01,  4.05189991e-01, -9.95159969e-02,\n",
              "         7.96540022e-01,  1.10299997e-01, -7.60530010e-02,\n",
              "        -9.04339999e-02,  1.50210001e-02, -1.13699996e+00,\n",
              "         1.68030000e+00, -3.44240010e-01,  7.75380015e-01,\n",
              "        -1.87179995e+00, -1.71480000e-01,  3.19559991e-01,\n",
              "         9.30619985e-02,  4.99599986e-03,  2.57160008e-01,\n",
              "         5.22069991e-01, -5.25479972e-01, -9.31439996e-01,\n",
              "        -1.05530000e+00,  1.44009995e+00,  3.08070004e-01,\n",
              "        -8.48720014e-01,  1.99860001e+00,  1.07879996e-01,\n",
              "        -2.36330003e-01, -1.79780006e-01],\n",
              "       [-1.44250005e-01,  1.08769998e-01, -5.04079998e-01,\n",
              "         1.30040005e-01, -3.32010001e-01, -3.20479989e-01,\n",
              "         2.97390014e-01, -7.12400019e-01,  3.34750004e-02,\n",
              "         9.94329989e-01,  3.62639993e-01,  5.06850004e-01,\n",
              "         7.31930017e-01, -2.41139993e-01,  1.50380000e-01,\n",
              "        -4.77869987e-01, -4.27029997e-01,  4.40690011e-01,\n",
              "         6.04210019e-01,  1.31159997e+00, -1.11370003e+00,\n",
              "        -2.87270010e-01,  9.27730024e-01,  1.10169995e+00,\n",
              "         6.83499992e-01,  7.74720013e-01, -1.09430003e+00,\n",
              "         7.30820000e-02,  5.16399980e-01, -7.26750016e-01,\n",
              "        -4.78219986e-01,  3.00709993e-01, -1.25520003e+00,\n",
              "         1.45210004e+00, -5.23580015e-01, -6.01639986e-01,\n",
              "         1.02830005e+00, -7.18789995e-01,  8.86950016e-01,\n",
              "         9.14460003e-01,  5.63239992e-01, -6.15079999e-01,\n",
              "        -8.84859979e-01, -1.66999996e-01, -2.84550011e-01,\n",
              "         3.06890011e-01,  2.58060008e-01,  2.68999994e-01,\n",
              "         1.15429997e+00,  1.04929996e+00],\n",
              "       [ 2.02140003e-01, -6.42769992e-01, -1.23910002e-01,\n",
              "         5.66860020e-01, -8.67120028e-01, -6.10140026e-01,\n",
              "         4.56099987e-01, -7.16139972e-01, -4.02330011e-01,\n",
              "         1.28009999e+00, -4.70030010e-01, -3.52230012e-01,\n",
              "        -5.34430027e-01, -9.71530020e-01, -1.82520002e-01,\n",
              "        -1.50339997e+00, -8.49960029e-01, -3.83500010e-01,\n",
              "         2.54000008e-01, -3.77180010e-01, -5.29569983e-01,\n",
              "        -3.30669999e-01,  5.42389989e-01, -7.89260030e-01,\n",
              "        -1.08299994e+00,  8.37059975e-01, -1.01470006e+00,\n",
              "         3.00720006e-01,  2.97369987e-01,  4.18839991e-01,\n",
              "         1.81190002e+00,  2.11960003e-01, -1.54809996e-01,\n",
              "         1.75979996e+00, -3.82400006e-02, -1.54589999e+00,\n",
              "         5.14880002e-01, -3.66109997e-01, -7.84400031e-02,\n",
              "        -1.44659996e-01, -2.76839994e-02, -7.91949987e-01,\n",
              "        -5.34739971e-01,  5.11849999e-01, -1.02090001e+00,\n",
              "        -1.96940005e+00, -2.80900002e-01,  1.09060001e+00,\n",
              "         8.76600027e-01,  1.30879998e+00],\n",
              "       [ 8.50510001e-01,  1.08169997e+00, -1.42560005e+00,\n",
              "         2.10170001e-01, -7.30710030e-01, -1.75070000e+00,\n",
              "        -3.45400006e-01,  7.29110003e-01, -8.78799975e-01,\n",
              "         7.34329998e-01,  8.61029983e-01,  6.53699994e-01,\n",
              "        -8.12210023e-01, -1.34580004e+00,  1.86780006e-01,\n",
              "        -1.81359994e+00,  2.69360006e-01, -8.14890027e-01,\n",
              "        -4.78680015e-01, -8.48909974e-01, -9.13200021e-01,\n",
              "         1.84540004e-01,  4.66739984e-05,  3.94510001e-01,\n",
              "        -9.36550021e-01, -2.65320003e-01, -8.22099984e-01,\n",
              "         1.17770001e-01, -1.94169998e-01,  4.90339994e-01,\n",
              "         2.53870010e+00, -1.09860003e+00, -1.53040004e+00,\n",
              "        -1.24750003e-01, -6.06379993e-02, -1.15859997e+00,\n",
              "         5.58729991e-02,  4.00700003e-01,  8.47880006e-01,\n",
              "         6.23160005e-01,  1.07589996e+00,  1.82210002e-02,\n",
              "         1.06340003e+00, -1.63759995e+00, -1.11839998e+00,\n",
              "        -8.63569975e-01, -9.29880023e-01, -1.72660005e+00,\n",
              "         1.64460003e+00,  8.35399985e-01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 3.49570006e-01,  4.01470006e-01, -1.25610000e-02,\n",
              "         1.37429997e-01,  4.00799990e-01,  4.66820002e-01,\n",
              "        -9.74299982e-02, -2.45480007e-03, -3.35640013e-01,\n",
              "        -4.63900017e-03, -5.91010004e-02,  2.75319993e-01,\n",
              "        -3.97399992e-01, -2.92670012e-01,  9.74420011e-01,\n",
              "         4.18799996e-01,  1.83950007e-01, -2.06019998e-01,\n",
              "        -6.14369996e-02, -6.15760028e-01, -5.34709990e-01,\n",
              "         4.15360004e-01,  3.48509997e-01, -3.18780005e-01,\n",
              "         2.74040014e-01, -1.83200002e+00, -8.23629975e-01,\n",
              "         4.88160014e-01,  1.13720000e+00, -3.80250007e-01,\n",
              "         3.81139994e+00,  2.55100012e-01, -7.06369996e-01,\n",
              "        -2.58199990e-01,  4.09290008e-02, -9.73780006e-02,\n",
              "         7.95710027e-01, -4.94839996e-01,  1.08700000e-01,\n",
              "         1.48379996e-01, -1.83899999e-01,  1.33120000e-01,\n",
              "         2.14690000e-01,  5.39319992e-01, -1.93379998e-01,\n",
              "        -4.22160000e-01, -6.14109993e-01,  7.03740001e-01,\n",
              "         5.75909972e-01,  4.35059994e-01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [-4.38610017e-02,  1.31830001e+00, -3.71499993e-02,\n",
              "         8.54780018e-01,  1.22120000e-01, -7.73840010e-01,\n",
              "         2.59000003e-01, -4.76760000e-01, -3.36950004e-01,\n",
              "         4.81139988e-01,  3.39450002e-01,  1.33000004e+00,\n",
              "         2.36300007e-01, -4.00440007e-01, -6.01320006e-02,\n",
              "        -9.06350017e-02, -1.35120004e-01, -2.44010001e-01,\n",
              "        -2.96429992e-01,  2.47480005e-01, -1.89469993e-01,\n",
              "        -3.12689990e-01,  8.19369972e-01,  4.42629993e-01,\n",
              "         3.16819996e-01, -3.26539993e-01, -1.01080000e+00,\n",
              "         1.03219999e-02,  2.36650005e-01, -8.76869977e-01,\n",
              "         1.96200001e+00,  2.95880008e-02, -4.05420005e-01,\n",
              "         1.26220000e+00, -2.61810005e-01, -8.54529977e-01,\n",
              "         8.02929997e-01, -1.13300002e+00,  6.19040012e-01,\n",
              "         6.80570006e-01,  9.75849986e-01, -3.72309983e-02,\n",
              "        -2.54099995e-01, -4.69520003e-01,  5.77900000e-02,\n",
              "        -1.46610007e-01, -1.59979999e-01, -8.62749994e-01,\n",
              "         1.23769999e+00,  8.74260008e-01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [ 2.96050012e-01, -1.38410002e-01,  4.37740013e-02,\n",
              "        -3.87439996e-01,  1.22620001e-01, -6.51799977e-01,\n",
              "        -2.82400012e-01,  9.03119966e-02, -5.51859975e-01,\n",
              "         3.20600003e-01,  3.74220009e-03,  9.32290018e-01,\n",
              "        -2.20339999e-01, -2.19219998e-01,  9.21700001e-01,\n",
              "         7.57239997e-01,  8.48919988e-01, -4.21970012e-03,\n",
              "         5.36260009e-01, -1.26670003e+00, -6.10279977e-01,\n",
              "         1.66999996e-01,  8.27530026e-01,  6.57649994e-01,\n",
              "         4.89589989e-01, -1.97440004e+00, -1.14900005e+00,\n",
              "        -2.14609995e-01,  8.05390000e-01, -1.47449994e+00,\n",
              "         3.74900007e+00,  1.01409996e+00, -1.12930000e+00,\n",
              "        -5.26610017e-01, -1.20290004e-01, -2.79309988e-01,\n",
              "         6.50919974e-02, -4.36390005e-02,  6.04260027e-01,\n",
              "        -2.08920002e-01, -4.57390010e-01,  1.04409996e-02,\n",
              "         4.14579988e-01,  6.89000010e-01,  1.44679993e-01,\n",
              "        -3.19730006e-02, -4.80730012e-02, -1.12790003e-04,\n",
              "         1.38540000e-01,  9.69540000e-01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  0.00000000e+00],\n",
              "       [-5.12589999e-02,  5.35160005e-01,  1.99430004e-01,\n",
              "         5.37800014e-01, -3.87230009e-01, -1.01409996e+00,\n",
              "         1.72039998e+00,  1.41709996e-02,  5.59820002e-03,\n",
              "         1.98510006e-01,  9.14309978e-01, -1.79509997e-01,\n",
              "         2.80389994e-01,  7.72440016e-01, -6.45060003e-01,\n",
              "         5.16279995e-01, -1.29529998e-01, -3.00080001e-01,\n",
              "         8.55560005e-01,  2.87209988e-01, -9.51579988e-01,\n",
              "         1.12329997e-01,  7.55140036e-02,  3.52849990e-01,\n",
              "        -4.91320014e-01,  1.58630002e+00, -8.32430005e-01,\n",
              "         1.20039999e+00,  9.09049988e-01,  7.13980019e-01,\n",
              "        -3.75869989e-01, -2.11109996e-01,  4.39949989e-01,\n",
              "        -3.59270006e-01, -4.11119998e-01,  3.07630002e-01,\n",
              "         6.21089995e-01, -9.46389973e-01,  2.47860000e-01,\n",
              "         8.83499980e-01,  6.13720000e-01,  4.02310014e-01,\n",
              "         5.04719973e-01, -1.05229998e+00, -3.38970006e-01,\n",
              "        -7.10780025e-01,  1.96899995e-01,  2.95049995e-01,\n",
              "         8.24090004e-01,  1.18519998e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Agora que j√° est√° tudo pronto, o c√≥digo abaixo cria a rede neural recorrente do tipo LSTM"
      ],
      "metadata": {
        "id": "nZv16NUGnmWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#rede neural recorrente LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, embeddings_initializer=Constant(embedding_matrix), input_length=seq_length, trainable=False))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "metadata": {
        "id": "vspMjfA_ldVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#compila√ß√£o da rede neural\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9pGXTPUmlgDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinamento\n",
        "model.fit(X, y, epochs=300, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xDUXd3eliBD",
        "outputId": "9843e69c-2461-447c-c86d-81aec78e5700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 - 3s - loss: 2.6913 - accuracy: 0.1000 - 3s/epoch - 3s/step\n",
            "Epoch 2/300\n",
            "1/1 - 0s - loss: 2.5981 - accuracy: 0.2000 - 14ms/epoch - 14ms/step\n",
            "Epoch 3/300\n",
            "1/1 - 0s - loss: 2.5071 - accuracy: 0.4000 - 15ms/epoch - 15ms/step\n",
            "Epoch 4/300\n",
            "1/1 - 0s - loss: 2.4175 - accuracy: 0.4000 - 14ms/epoch - 14ms/step\n",
            "Epoch 5/300\n",
            "1/1 - 0s - loss: 2.3283 - accuracy: 0.5000 - 12ms/epoch - 12ms/step\n",
            "Epoch 6/300\n",
            "1/1 - 0s - loss: 2.2389 - accuracy: 0.7000 - 21ms/epoch - 21ms/step\n",
            "Epoch 7/300\n",
            "1/1 - 0s - loss: 2.1489 - accuracy: 0.8000 - 21ms/epoch - 21ms/step\n",
            "Epoch 8/300\n",
            "1/1 - 0s - loss: 2.0578 - accuracy: 0.8000 - 21ms/epoch - 21ms/step\n",
            "Epoch 9/300\n",
            "1/1 - 0s - loss: 1.9655 - accuracy: 0.7000 - 18ms/epoch - 18ms/step\n",
            "Epoch 10/300\n",
            "1/1 - 0s - loss: 1.8722 - accuracy: 0.7000 - 16ms/epoch - 16ms/step\n",
            "Epoch 11/300\n",
            "1/1 - 0s - loss: 1.7780 - accuracy: 0.7000 - 21ms/epoch - 21ms/step\n",
            "Epoch 12/300\n",
            "1/1 - 0s - loss: 1.6832 - accuracy: 0.7000 - 18ms/epoch - 18ms/step\n",
            "Epoch 13/300\n",
            "1/1 - 0s - loss: 1.5884 - accuracy: 0.7000 - 22ms/epoch - 22ms/step\n",
            "Epoch 14/300\n",
            "1/1 - 0s - loss: 1.4940 - accuracy: 0.7000 - 19ms/epoch - 19ms/step\n",
            "Epoch 15/300\n",
            "1/1 - 0s - loss: 1.4005 - accuracy: 0.7000 - 23ms/epoch - 23ms/step\n",
            "Epoch 16/300\n",
            "1/1 - 0s - loss: 1.3084 - accuracy: 0.7000 - 20ms/epoch - 20ms/step\n",
            "Epoch 17/300\n",
            "1/1 - 0s - loss: 1.2183 - accuracy: 0.7000 - 18ms/epoch - 18ms/step\n",
            "Epoch 18/300\n",
            "1/1 - 0s - loss: 1.1307 - accuracy: 0.8000 - 19ms/epoch - 19ms/step\n",
            "Epoch 19/300\n",
            "1/1 - 0s - loss: 1.0460 - accuracy: 0.8000 - 21ms/epoch - 21ms/step\n",
            "Epoch 20/300\n",
            "1/1 - 0s - loss: 0.9646 - accuracy: 0.8000 - 18ms/epoch - 18ms/step\n",
            "Epoch 21/300\n",
            "1/1 - 0s - loss: 0.8869 - accuracy: 0.8000 - 18ms/epoch - 18ms/step\n",
            "Epoch 22/300\n",
            "1/1 - 0s - loss: 0.8132 - accuracy: 0.8000 - 19ms/epoch - 19ms/step\n",
            "Epoch 23/300\n",
            "1/1 - 0s - loss: 0.7436 - accuracy: 0.8000 - 18ms/epoch - 18ms/step\n",
            "Epoch 24/300\n",
            "1/1 - 0s - loss: 0.6782 - accuracy: 0.9000 - 20ms/epoch - 20ms/step\n",
            "Epoch 25/300\n",
            "1/1 - 0s - loss: 0.6171 - accuracy: 0.9000 - 28ms/epoch - 28ms/step\n",
            "Epoch 26/300\n",
            "1/1 - 0s - loss: 0.5603 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 27/300\n",
            "1/1 - 0s - loss: 0.5078 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 28/300\n",
            "1/1 - 0s - loss: 0.4597 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 29/300\n",
            "1/1 - 0s - loss: 0.4159 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 30/300\n",
            "1/1 - 0s - loss: 0.3765 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 31/300\n",
            "1/1 - 0s - loss: 0.3411 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 32/300\n",
            "1/1 - 0s - loss: 0.3094 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 33/300\n",
            "1/1 - 0s - loss: 0.2806 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 34/300\n",
            "1/1 - 0s - loss: 0.2540 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 35/300\n",
            "1/1 - 0s - loss: 0.2291 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 36/300\n",
            "1/1 - 0s - loss: 0.2054 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 37/300\n",
            "1/1 - 0s - loss: 0.1831 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 38/300\n",
            "1/1 - 0s - loss: 0.1623 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 39/300\n",
            "1/1 - 0s - loss: 0.1433 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 40/300\n",
            "1/1 - 0s - loss: 0.1263 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 41/300\n",
            "1/1 - 0s - loss: 0.1112 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 42/300\n",
            "1/1 - 0s - loss: 0.0979 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 43/300\n",
            "1/1 - 0s - loss: 0.0863 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 44/300\n",
            "1/1 - 0s - loss: 0.0761 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 45/300\n",
            "1/1 - 0s - loss: 0.0674 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 46/300\n",
            "1/1 - 0s - loss: 0.0600 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 47/300\n",
            "1/1 - 0s - loss: 0.0538 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 48/300\n",
            "1/1 - 0s - loss: 0.0487 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 49/300\n",
            "1/1 - 0s - loss: 0.0443 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 50/300\n",
            "1/1 - 0s - loss: 0.0406 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 51/300\n",
            "1/1 - 0s - loss: 0.0373 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 52/300\n",
            "1/1 - 0s - loss: 0.0344 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 53/300\n",
            "1/1 - 0s - loss: 0.0318 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 54/300\n",
            "1/1 - 0s - loss: 0.0294 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 55/300\n",
            "1/1 - 0s - loss: 0.0272 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 56/300\n",
            "1/1 - 0s - loss: 0.0253 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 57/300\n",
            "1/1 - 0s - loss: 0.0236 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 58/300\n",
            "1/1 - 0s - loss: 0.0221 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 59/300\n",
            "1/1 - 0s - loss: 0.0208 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 60/300\n",
            "1/1 - 0s - loss: 0.0195 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 61/300\n",
            "1/1 - 0s - loss: 0.0184 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 62/300\n",
            "1/1 - 0s - loss: 0.0174 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 63/300\n",
            "1/1 - 0s - loss: 0.0165 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 64/300\n",
            "1/1 - 0s - loss: 0.0156 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 65/300\n",
            "1/1 - 0s - loss: 0.0148 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 66/300\n",
            "1/1 - 0s - loss: 0.0141 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 67/300\n",
            "1/1 - 0s - loss: 0.0134 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 68/300\n",
            "1/1 - 0s - loss: 0.0128 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 69/300\n",
            "1/1 - 0s - loss: 0.0123 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 70/300\n",
            "1/1 - 0s - loss: 0.0117 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 71/300\n",
            "1/1 - 0s - loss: 0.0113 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 72/300\n",
            "1/1 - 0s - loss: 0.0109 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 73/300\n",
            "1/1 - 0s - loss: 0.0105 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 74/300\n",
            "1/1 - 0s - loss: 0.0101 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 75/300\n",
            "1/1 - 0s - loss: 0.0097 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 76/300\n",
            "1/1 - 0s - loss: 0.0094 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 77/300\n",
            "1/1 - 0s - loss: 0.0091 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 78/300\n",
            "1/1 - 0s - loss: 0.0088 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 79/300\n",
            "1/1 - 0s - loss: 0.0085 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 80/300\n",
            "1/1 - 0s - loss: 0.0083 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 81/300\n",
            "1/1 - 0s - loss: 0.0081 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 82/300\n",
            "1/1 - 0s - loss: 0.0078 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 83/300\n",
            "1/1 - 0s - loss: 0.0076 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 84/300\n",
            "1/1 - 0s - loss: 0.0074 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 85/300\n",
            "1/1 - 0s - loss: 0.0072 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 86/300\n",
            "1/1 - 0s - loss: 0.0070 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 87/300\n",
            "1/1 - 0s - loss: 0.0069 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 88/300\n",
            "1/1 - 0s - loss: 0.0067 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 89/300\n",
            "1/1 - 0s - loss: 0.0065 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 90/300\n",
            "1/1 - 0s - loss: 0.0064 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 91/300\n",
            "1/1 - 0s - loss: 0.0063 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 92/300\n",
            "1/1 - 0s - loss: 0.0061 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 93/300\n",
            "1/1 - 0s - loss: 0.0060 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 94/300\n",
            "1/1 - 0s - loss: 0.0059 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 95/300\n",
            "1/1 - 0s - loss: 0.0057 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 96/300\n",
            "1/1 - 0s - loss: 0.0056 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 97/300\n",
            "1/1 - 0s - loss: 0.0055 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 98/300\n",
            "1/1 - 0s - loss: 0.0054 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 99/300\n",
            "1/1 - 0s - loss: 0.0053 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 100/300\n",
            "1/1 - 0s - loss: 0.0052 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 101/300\n",
            "1/1 - 0s - loss: 0.0051 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 102/300\n",
            "1/1 - 0s - loss: 0.0050 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 103/300\n",
            "1/1 - 0s - loss: 0.0049 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 104/300\n",
            "1/1 - 0s - loss: 0.0048 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 105/300\n",
            "1/1 - 0s - loss: 0.0048 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 106/300\n",
            "1/1 - 0s - loss: 0.0047 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 107/300\n",
            "1/1 - 0s - loss: 0.0046 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 108/300\n",
            "1/1 - 0s - loss: 0.0045 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 109/300\n",
            "1/1 - 0s - loss: 0.0044 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 110/300\n",
            "1/1 - 0s - loss: 0.0044 - accuracy: 1.0000 - 14ms/epoch - 14ms/step\n",
            "Epoch 111/300\n",
            "1/1 - 0s - loss: 0.0043 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 112/300\n",
            "1/1 - 0s - loss: 0.0042 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 113/300\n",
            "1/1 - 0s - loss: 0.0042 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 114/300\n",
            "1/1 - 0s - loss: 0.0041 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 115/300\n",
            "1/1 - 0s - loss: 0.0040 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 116/300\n",
            "1/1 - 0s - loss: 0.0040 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 117/300\n",
            "1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 118/300\n",
            "1/1 - 0s - loss: 0.0039 - accuracy: 1.0000 - 15ms/epoch - 15ms/step\n",
            "Epoch 119/300\n",
            "1/1 - 0s - loss: 0.0038 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 120/300\n",
            "1/1 - 0s - loss: 0.0038 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 121/300\n",
            "1/1 - 0s - loss: 0.0037 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 122/300\n",
            "1/1 - 0s - loss: 0.0037 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 123/300\n",
            "1/1 - 0s - loss: 0.0036 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 124/300\n",
            "1/1 - 0s - loss: 0.0036 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 125/300\n",
            "1/1 - 0s - loss: 0.0035 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 126/300\n",
            "1/1 - 0s - loss: 0.0035 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 127/300\n",
            "1/1 - 0s - loss: 0.0034 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 128/300\n",
            "1/1 - 0s - loss: 0.0034 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 129/300\n",
            "1/1 - 0s - loss: 0.0033 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 130/300\n",
            "1/1 - 0s - loss: 0.0033 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 131/300\n",
            "1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 132/300\n",
            "1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 133/300\n",
            "1/1 - 0s - loss: 0.0032 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 134/300\n",
            "1/1 - 0s - loss: 0.0031 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 135/300\n",
            "1/1 - 0s - loss: 0.0031 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 136/300\n",
            "1/1 - 0s - loss: 0.0030 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 137/300\n",
            "1/1 - 0s - loss: 0.0030 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 138/300\n",
            "1/1 - 0s - loss: 0.0030 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 139/300\n",
            "1/1 - 0s - loss: 0.0029 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 140/300\n",
            "1/1 - 0s - loss: 0.0029 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 141/300\n",
            "1/1 - 0s - loss: 0.0029 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 142/300\n",
            "1/1 - 0s - loss: 0.0028 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 143/300\n",
            "1/1 - 0s - loss: 0.0028 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 144/300\n",
            "1/1 - 0s - loss: 0.0028 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 145/300\n",
            "1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 146/300\n",
            "1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 147/300\n",
            "1/1 - 0s - loss: 0.0027 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 148/300\n",
            "1/1 - 0s - loss: 0.0026 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 149/300\n",
            "1/1 - 0s - loss: 0.0026 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 150/300\n",
            "1/1 - 0s - loss: 0.0026 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 151/300\n",
            "1/1 - 0s - loss: 0.0026 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 152/300\n",
            "1/1 - 0s - loss: 0.0025 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 153/300\n",
            "1/1 - 0s - loss: 0.0025 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 154/300\n",
            "1/1 - 0s - loss: 0.0025 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 155/300\n",
            "1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 156/300\n",
            "1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 157/300\n",
            "1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 158/300\n",
            "1/1 - 0s - loss: 0.0024 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 159/300\n",
            "1/1 - 0s - loss: 0.0023 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 160/300\n",
            "1/1 - 0s - loss: 0.0023 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 161/300\n",
            "1/1 - 0s - loss: 0.0023 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 162/300\n",
            "1/1 - 0s - loss: 0.0023 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 163/300\n",
            "1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 164/300\n",
            "1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 165/300\n",
            "1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 166/300\n",
            "1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 167/300\n",
            "1/1 - 0s - loss: 0.0022 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 168/300\n",
            "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 169/300\n",
            "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 170/300\n",
            "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 171/300\n",
            "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 172/300\n",
            "1/1 - 0s - loss: 0.0021 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
            "Epoch 173/300\n",
            "1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 174/300\n",
            "1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 175/300\n",
            "1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
            "Epoch 176/300\n",
            "1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 177/300\n",
            "1/1 - 0s - loss: 0.0020 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 178/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
            "Epoch 179/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 180/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 181/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 182/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 183/300\n",
            "1/1 - 0s - loss: 0.0019 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 184/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 30ms/epoch - 30ms/step\n",
            "Epoch 185/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 186/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 187/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 188/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 189/300\n",
            "1/1 - 0s - loss: 0.0018 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 190/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 191/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 192/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 193/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 194/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 195/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 196/300\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 31ms/epoch - 31ms/step\n",
            "Epoch 197/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 32ms/epoch - 32ms/step\n",
            "Epoch 198/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 199/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 200/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 201/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 202/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 203/300\n",
            "1/1 - 0s - loss: 0.0016 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 204/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 205/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 206/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 207/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 208/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 209/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 210/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 211/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 212/300\n",
            "1/1 - 0s - loss: 0.0015 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 213/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 28ms/epoch - 28ms/step\n",
            "Epoch 214/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 215/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 27ms/epoch - 27ms/step\n",
            "Epoch 216/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 217/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 218/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 219/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 220/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 221/300\n",
            "1/1 - 0s - loss: 0.0014 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 222/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 223/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 224/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 225/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 226/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 227/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 228/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 229/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 230/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 231/300\n",
            "1/1 - 0s - loss: 0.0013 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 232/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 29ms/epoch - 29ms/step\n",
            "Epoch 233/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 234/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 235/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 236/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 237/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 238/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 239/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 240/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 241/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 242/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 243/300\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 244/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 245/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 246/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 247/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 248/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 249/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 250/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 251/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 252/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 253/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 254/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 255/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 256/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 257/300\n",
            "1/1 - 0s - loss: 0.0011 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 258/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 259/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 260/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 261/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 262/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 263/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 264/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 265/300\n",
            "1/1 - 0s - loss: 0.0010 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 266/300\n",
            "1/1 - 0s - loss: 9.9450e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 267/300\n",
            "1/1 - 0s - loss: 9.8828e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 268/300\n",
            "1/1 - 0s - loss: 9.8216e-04 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 269/300\n",
            "1/1 - 0s - loss: 9.7610e-04 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 270/300\n",
            "1/1 - 0s - loss: 9.7011e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 271/300\n",
            "1/1 - 0s - loss: 9.6413e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 272/300\n",
            "1/1 - 0s - loss: 9.5824e-04 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
            "Epoch 273/300\n",
            "1/1 - 0s - loss: 9.5240e-04 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 274/300\n",
            "1/1 - 0s - loss: 9.4659e-04 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 275/300\n",
            "1/1 - 0s - loss: 9.4090e-04 - accuracy: 1.0000 - 26ms/epoch - 26ms/step\n",
            "Epoch 276/300\n",
            "1/1 - 0s - loss: 9.3522e-04 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 277/300\n",
            "1/1 - 0s - loss: 9.2966e-04 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 278/300\n",
            "1/1 - 0s - loss: 9.2410e-04 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 279/300\n",
            "1/1 - 0s - loss: 9.1857e-04 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 280/300\n",
            "1/1 - 0s - loss: 9.1313e-04 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 281/300\n",
            "1/1 - 0s - loss: 9.0775e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 282/300\n",
            "1/1 - 0s - loss: 9.0235e-04 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 283/300\n",
            "1/1 - 0s - loss: 8.9709e-04 - accuracy: 1.0000 - 25ms/epoch - 25ms/step\n",
            "Epoch 284/300\n",
            "1/1 - 0s - loss: 8.9185e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 285/300\n",
            "1/1 - 0s - loss: 8.8664e-04 - accuracy: 1.0000 - 24ms/epoch - 24ms/step\n",
            "Epoch 286/300\n",
            "1/1 - 0s - loss: 8.8147e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 287/300\n",
            "1/1 - 0s - loss: 8.7641e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 288/300\n",
            "1/1 - 0s - loss: 8.7136e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 289/300\n",
            "1/1 - 0s - loss: 8.6633e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 290/300\n",
            "1/1 - 0s - loss: 8.6135e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 291/300\n",
            "1/1 - 0s - loss: 8.5644e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 292/300\n",
            "1/1 - 0s - loss: 8.5156e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 293/300\n",
            "1/1 - 0s - loss: 8.4675e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 294/300\n",
            "1/1 - 0s - loss: 8.4192e-04 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 295/300\n",
            "1/1 - 0s - loss: 8.3722e-04 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 296/300\n",
            "1/1 - 0s - loss: 8.3253e-04 - accuracy: 1.0000 - 23ms/epoch - 23ms/step\n",
            "Epoch 297/300\n",
            "1/1 - 0s - loss: 8.2783e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 298/300\n",
            "1/1 - 0s - loss: 8.2321e-04 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 299/300\n",
            "1/1 - 0s - loss: 8.1869e-04 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
            "Epoch 300/300\n",
            "1/1 - 0s - loss: 8.1412e-04 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x785e1f9637c0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A √∫ltima fun√ß√£o √© respons√°vel por criar texto completando o texto que for passado."
      ],
      "metadata": {
        "id": "Taz9VmyGoNMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_seq_length, diversity=0.7):\n",
        "    generated_words = []\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_seq_length, padding='pre')\n",
        "        predicted = model.predict(token_list, verbose=0)[0]\n",
        "\n",
        "        preds = np.asarray(predicted).astype('float64')\n",
        "        preds = np.log(preds) / diversity\n",
        "        exp_preds = np.exp(preds)\n",
        "        preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "        probas = np.random.multinomial(1, preds, 1)\n",
        "        predicted_word_index = np.argmax(probas)\n",
        "\n",
        "        predicted_word = tokenizer.index_word.get(predicted_word_index, '')\n",
        "        if predicted_word in generated_words:\n",
        "            continue\n",
        "        generated_words.append(predicted_word)\n",
        "        seed_text += \" \" + predicted_word\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "O8UiSP-rlj2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Uma rede neural √©\"\n",
        "generated_text = generate_text(seed_text, 10, model, seq_length, diversity=0.7)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PdHoJ48lmYB",
        "outputId": "8ec6f3b8-d594-48ef-d765-3c11a844fcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uma rede neural √© forma de simular no computador o funcionamento do c√©rebro humano\n"
          ]
        }
      ]
    }
  ]
}