# Repositório de Projetos de NLP, Machine Learning e LLM

Bem-vindo ao meu repositório de projetos de Processamento de Linguagem Natural (PLN), Machine Learning e Modelos de Linguagem de Grande Escala (LLM). Este repositório contém uma coleção de notebooks do Google Colab que exemplificam diversas técnicas e aplicações dessas áreas da Inteligência Artificial, sobretudo da IA Generativa.

<div align="center">
  
| ![I'm a talking robot You can trust me](Arquivos/talking_robot.gif) |
|:--:|
| *I'm a talking robot. You can trust me.* |

</div>

## Sumário

1. [Fundamentos de Processamento de Linguagem Natural](#fundamentos-de-processamento-de-linguagem-natural)
2. [Machine Learning e Deep Learning para NLP](#machine-learning-e-deep-learning-para-nlp)
3. [Fine-Tunning em Large Language Models](#fine-tunning-em-large-language-models)
4. [Aplicações de Modelos de Linguagem](#aplicações-de-modelos-de-linguagem)
5. [Referências e Contribuições](#referências-e-contribuições)



## Fundamentos de Processamento de Linguagem Natural

Aqui tem-se os conceitos básicos de Natural Language Processing (NLP), incluindo tokenização, remoção de stopwords, stemming e lematização. Os notebooks demonstram como essas técnicas podem ser aplicadas em textos simples para preparar dados textuais para tarefas de Machine Learning.

* [Pré-processamento de texto]()
* [NLP com a biblioteca NLTK]()
* [NLP com a biblioteca spaCy]()





## Machine Learning e Deep Learning para NLP

Os notebboks desta seção exploram como as áreas de ML e DL, assim como as Redes Neurais colaboram com as aplicações de Processamento de Linguagem Natural. Aqui foram utilizandas bibliotecas poderosas de machine learning como scikit-learn e Keras na construção dos códigos..

* [Machine Learning para classificação de texto]()
* [Criação de rede neural artificial]()
* [Criação de rede neural artificial com embeddings]()
* [Criando uma LSTM para NLP na prática]()




## Fine-Tunning em Large Language Models

Para esses notebooks são apresentados exemplos que envolvem ajustar um modelo pré-treinado em uma nova tarefa específica, utilizando um conjunto de dados menor e especializado. Esse processo adapta o modelo às necessidades particulares, melhorando sua performance sem precisar treinar do zero.

* [Fine-tunning na prática com GPT2]()
* [Fine-Tuning em uma LLM usando o BERT]()
* [Implementando Low-Rank Adaptation (LoRA)]()



## Aplicações de Modelos de Linguagem

Projetos que exploram os módulos disponíveis na biblioteca da empresa [*Hugging Face*](https://huggingface.co/). Os notebooks seguintes possuem demonstração de diversas tarefas de Modelos de Linguagem, como tradução de texto, sumarização, perguntas e respostas, entre outros. São aplicações poderosas no domínio da Inteligência Artificial, porém com alto nível de abstração.

* [Geração de texto com GPT2]()
* [Compreensão de texto com RoBERTa]()
* [Tradução automática de texto com OPUS]()
* [Perguntas e respostas com RoBERTa]()
* [Perguntas e respostas com BERT]()
* [Sumarização de texto com BART]()
* [Sumarização de texto com Transformers]()
* [Sumarização de texto com T5]()
* [Preenchimento de máscara com GPTNeo]()
* [Preenchimento de máscara com BERTimbau]()
* [Preenchimento de máscara com RoBERTa]()
* [Modelagem de tópicos com BERT]()
* [Gerando Sequências de texto com GPT2]()
* [Correção gramatical de texto com T5]()



#### GPT da OpenIA:

* [Testando o modelo GPT da OpenIA]()
* [Agente autônomo para LLM com GPT da OpenIA]()


#### Análise de Sentimentos:

* [Análise de Sentimentos com rede neural LSTM]()
* [Análise de Sentimentos a base de regras com VADER]()
* [Análise de Sentimentos: Supervisionado x Regras]()


---
 
## Referências e Contribuições

Boa parte dos códigos são práticas realizadas em tutoriais e cursos feitos de forma online. Segue abaixo lista de recursos que foram consultados e links de indicação de conteúdo que podem ser utilizados para um estudo mais abrangente em NLP e LLMs:

+ [Formação Processamento de Linguagem Natural e LLM (Udemy)](https://www.udemy.com/course/formacao-processamento-de-linguagem-natural-nlp/?couponCode=THANKSLEARNER24)
+ [LLMs: Dommine GPT, Gemini, BERT e Muito Mais - 2024 (Udemy)](https://www.udemy.com/course/domine-llm/?couponCode=KEEPLEARNING)
+ [PROF. FABIO SANTOS (YouTube)](https://www.youtube.com/@Prof.FabioSantos)

### Licença

Este repositório não está licenciado.

